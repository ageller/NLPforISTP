{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787b47bf",
   "metadata": {},
   "source": [
    "# NLP Analysis Pipeline\n",
    "\n",
    "```\n",
    "conda create --name NLP -c conda-forge python=3.10 jupyter pandas numpy matplotlib openpyxl nltk gensim pyldavis spacy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you are running this for the first time on a new installation, uncomment below and run this cell\n",
    "## (This only needs to be run once.)\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "# import spacy\n",
    "# spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564dc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to autoreload <-- only necessary while coding/debugging\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NLPforISP import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c272b2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data file with multiple sheets\n",
    "filename = 'data/ITP_CourseArtifacts_June 2021_END_of_Course_DeIDENTIFIED.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a724dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = np.arange(10) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ae462",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results1 = runNLPPipeline(filename, sheet = 'Course Meta SelfEff', column_number = 1, num_topics = num_topics,\n",
    "    workers = 6, random_seed = 1234, n_answers = 20, n_sentences = 3,  \n",
    "    kmeans_tfidf_ngram_range = (1,2), kmeans_tfidf_min_df = 0.001, kmeans_num_words_for_label = 10,\n",
    "    #no_below = 15, no_above = 1, keep_n = int(1e5)\n",
    "    #run_lda = False, run_ngrams = False, \n",
    "    coherence_method = \"combined\", cvals = ['c_v', 'u_mass'],\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33d8fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results2 = runNLPPipeline(filename, sheet = 'Course Meta App', column_number = 1, num_topics = num_topics,\n",
    "    workers = 6, random_seed = 1234, n_answers = 20, n_sentences = 3,\n",
    "    kmeans_tfidf_ngram_range = (1,2), kmeans_tfidf_min_df = 0.001, kmeans_num_words_for_label = 10,\n",
    "    #no_below = 15, no_above = 1, keep_n = int(1e5)\n",
    "    #run_lda = False, run_ngrams = False, \n",
    "    coherence_method = \"combined\", cvals = ['c_v', 'u_mass'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7033a28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# combined\n",
    "df1 = pd.read_excel(filename, 'Course Meta SelfEff')\n",
    "df1.rename(columns = {df1.columns[1]: 'answer_text'}, inplace = True)\n",
    "\n",
    "df2 = pd.read_excel(filename, 'Course Meta App')\n",
    "df2.rename(columns = {df2.columns[1]: 'answer_text'}, inplace = True)\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "# remove duplicates (there are a few)\n",
    "df['answer_text'] = df['answer_text'].str.strip()\n",
    "df = df.drop_duplicates(subset = [\"answer_text\"], keep = False).reset_index(drop = True) \n",
    "\n",
    "results_combined = runNLPPipeline(df = df, sheet = \"combined\", column_number = 1, num_topics = num_topics,\n",
    "    workers = 6, random_seed = 1234, n_answers = 20, n_sentences = 3,\n",
    "    kmeans_tfidf_ngram_range = (1,2), kmeans_tfidf_min_df = 0.001, kmeans_num_words_for_label = 10,\n",
    "    coherence_method = \"combined\", cvals = ['c_v', 'u_mass'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f10a1a",
   "metadata": {},
   "source": [
    "# Try with TF-IDF in LDA \n",
    "\n",
    "Reading online says this is not recommended ... and it gives strange results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2954d1f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results1_tfidf = runNLPPipeline(filename, sheet = 'Course Meta SelfEff', column_number = 1, num_topics = num_topics,\n",
    "    workers = 6, random_seed = 1234, n_answers = 20, n_sentences = 3,  \n",
    "    coherence_method = \"combined\", use_tfidf = {'lsi':True, 'lda':False},  cvals = ['c_v', 'u_mass'],\n",
    "    run_kmeans = False, run_lda = True, run_lsi = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ccb96e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results2_tfidf = runNLPPipeline(filename, sheet = 'Course Meta App', column_number = 1, num_topics = num_topics,\n",
    "    workers = 6, random_seed = 1234, n_answers = 20, n_sentences = 3,\n",
    "    coherence_method = \"combined\", use_tfidf = True, cvals = ['c_v', 'u_mass'],\n",
    "    run_kmeans = False, run_lda = True, run_lsi = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e735cd2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# combined\n",
    "df1 = pd.read_excel(filename, 'Course Meta SelfEff')\n",
    "df1.rename(columns = {df1.columns[1]: 'answer_text'}, inplace = True)\n",
    "\n",
    "df2 = pd.read_excel(filename, 'Course Meta App')\n",
    "df2.rename(columns = {df2.columns[1]: 'answer_text'}, inplace = True)\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "# remove duplicates (there are a few)\n",
    "df['answer_text'] = df['answer_text'].str.strip()\n",
    "df = df.drop_duplicates(subset = [\"answer_text\"], keep = False).reset_index(drop = True) \n",
    "\n",
    "results_combined_tfidf = runNLPPipeline(df = df, sheet = \"combined\", column_number = 1, num_topics = num_topics,\n",
    "    workers = 6, random_seed = 1234, n_answers = 20, n_sentences = 3,\n",
    "    coherence_method = \"combined\", use_tfidf = True, cvals = ['c_v', 'u_mass'],\n",
    "    run_kmeans = False, run_lda = True, run_lsi = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67be641b",
   "metadata": {},
   "source": [
    "## Visualize with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9a653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0392adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.gensim_models.prepare(results1['lda']['model'][results1['lda']['best_index']], \n",
    "                               results1['bow_corpus'], results1['dictionary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a213d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.gensim_models.prepare(results2['lda']['model'][results2['lda']['best_index']], \n",
    "                               results2['bow_corpus'], results2['dictionary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208954d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
