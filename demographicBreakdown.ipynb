{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5626b0ef",
   "metadata": {},
   "source": [
    "# Determine the demographic breakdown of the participants\n",
    "\n",
    "We want to know the most frequent categories of the participants, including all overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9daa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a file that combines results from multiple surveys. \n",
    "# the challenge is going to be identifying the useful columns and what questions they belong to!\n",
    "df = pd.read_spss('data/Consent_Pre_Post_MERGE.sav')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77941d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.values\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think these are the important columns\n",
    "# They appear to come from the SP22_RQ2_Participant_ISTP.docx file\n",
    "# missing faculty status question\n",
    "useCols = [\n",
    "    'primerole_march22', 'discipline_march22', 'institution_march22', 'gender_march22','firstgen0322', 'army',\n",
    "    'institution1', 'institution8', 'institution9', 'institution10', 'institution11', 'institution12', 'institution13',\n",
    "    'race_nativA_march22', 'race_asianA_march22',\n",
    "    'race_africanA_march22', 'race_asianE_march22', 'race_latinx_march22',\n",
    "    'race_MENA_march22', 'race_pi_march22', 'race_asianS_march22',\n",
    "    'race_asianSE_march22', 'race_white_march22', 'race_multi_march22'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa44570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedf = df[useCols].fillna(0)\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRange(col):\n",
    "    return [np.min(usedf[col].values), np.max(usedf[col].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a29166",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,c in enumerate(useCols):\n",
    "    print(c, findRange(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c60541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping for the answer from numbers to words from the SP22_RQ2_Participant_ISTP.docx file\n",
    "roleMap = {\n",
    "    1:'Faculty member, lecturer, instructor, or adjunct faculty',\n",
    "    2:'Graduate student',\n",
    "    3:'Posdoctoral scholar',\n",
    "    4:'Staff member',\n",
    "    5:'Other (role)'\n",
    "}\n",
    "disciplineMap = {\n",
    "    1:'Agriculture and natural resource sciences',\n",
    "    2:'Arts',\n",
    "    3:'Biological and life sciences',\n",
    "    4:'Business and management science',\n",
    "    5:'Chemistry',\n",
    "    6:'Computer, information, and technological sciences',\n",
    "    7:'Earth, environmental, atmospheric, and ocean sciences',\n",
    "    8:'Education',\n",
    "    9:'Engineering',\n",
    "    10:'Humanities',\n",
    "    11:'Law',\n",
    "    12:'Mathematics and Statistics',\n",
    "    13:'Medical sciences',\n",
    "    14:'Physical sciences',\n",
    "    15:'Psychology',\n",
    "    16:'Social, behavioral, and economic sciences (not including psychology)',\n",
    "    17:'Other (discipline)'\n",
    "}\n",
    "institutionMap = {\n",
    "    1:'Community college / 2-year institution',\n",
    "    7:'Comprehensive or Regional University (e.g., smaller state school, schools that offer mostly bachelor or masters degrees)',\n",
    "    8:'Liberal arts college',\n",
    "    9:'Research University',\n",
    "    10:'Technical college', \n",
    "    11:'Other (institution)'\n",
    "}\n",
    "genderMap = {\n",
    "    1:'Gender queer or gender non-conforming', \n",
    "    8:'Man',\n",
    "    9:'Nonbinary',\n",
    "    10:'Transman',\n",
    "    14:'Transwoman', \n",
    "    11:'Woman', \n",
    "    12:'I self-describe as (gender)',\n",
    "    13:'I prefer not to respond (gender).'\n",
    "}\n",
    "firstgenMap = {1:'first gen'}\n",
    "armyMap = {1:'veteran'}\n",
    "\n",
    "# these are checkboxes so I will keep each individual column\n",
    "insitutionTypeMap = {\n",
    "    1:'Asian American and Pacific Islander Serving Institution (AAPISI)',\n",
    "    8:'Hispanic Serving Institution (HSI)', \n",
    "    9:'Historically Black College and University (HBCU)', \n",
    "    10:'Predominantly White Institution (PWI)',\n",
    "    11:'Tribal College/University',\n",
    "    12:'Other Minority Serving Institution (MSI)',\n",
    "    13:'I am not sure (institution)'\n",
    "}\n",
    "raceMap = {\n",
    "    1:'Alaska Native, American Indian, Native American or Indigenous',\n",
    "    14:'Asian American',\n",
    "    15:'Black or African American',\n",
    "    16:'East Asian',\n",
    "    17:'Latina/o/x or Hispanic',\n",
    "    18:'Middle Eastern or Northern African',\n",
    "    19:'Pacific Islander',\n",
    "    20:'South Asian',\n",
    "    21:'Southeast Asian',\n",
    "    22:'White',\n",
    "    23:'Multiracial',\n",
    "    24:'I self-describe as (race):',\n",
    "    25:'I prefer not to respond (race).'\n",
    "}\n",
    "raceMap2 = {\n",
    "    'nativA':'Alaska Native, American Indian, Native American or Indigenous',\n",
    "    'asianA':'Asian American',\n",
    "    'africanA':'Black or African American',\n",
    "    'asianE':'East Asian',\n",
    "    'latinx':'Latina/o/x or Hispanic',\n",
    "    'MENA':'Middle Eastern or Northern African',\n",
    "    'pi':'Pacific Islander',\n",
    "    'asianS':'South Asian',\n",
    "    'asianSE':'Southeast Asian',\n",
    "    'white':'White',\n",
    "    'multi':'Multiracial',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ff20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "list(itertools.combinations(useCols, len(useCols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d02aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all the columns and groupby all the other columns to get the overlaps\n",
    "# if i == 0, then we find the overlaps of all columns\n",
    "# if i > 0, then we ignore any columns < i, and replace their values with -1\n",
    "# using method from : https://stackoverflow.com/questions/35268817/unique-combinations-of-values-in-selected-columns-in-pandas-data-frame-and-count\n",
    "\n",
    "# I need to allow any 1 column to be anything, then any 2 columns, and so on.\n",
    "n = 0\n",
    "for i in np.arange(1, len(useCols)):\n",
    "    # get all the combinations of i columns in useCols\n",
    "    itr = list(itertools.combinations(useCols, i))\n",
    "    print(i, len(itr))\n",
    "    \n",
    "    # these columns will be used in groupby while others will be anything\n",
    "    for useColList in itr:\n",
    "        g = usedf.groupby(list(useColList)).size().reset_index().rename(columns = {0:'count'})\n",
    "\n",
    "        # add the missing column(s) as -1 (meaning could be anything)\n",
    "        for cc in useCols:\n",
    "            if (cc not in useColList):\n",
    "                g.insert(0, cc, -1)\n",
    "    \n",
    "    \n",
    "        # for the checkbox answers, I only care about those that have multiple rows with values > 0\n",
    "        # so I will drop any of the groupdf rows that have only -1s and 0s with one non-zero value\n",
    "\n",
    "        # remove the count\n",
    "        count = g.pop('count')\n",
    "\n",
    "        # get the trim condition\n",
    "        condition = g.gt(0).sum(axis = 1).gt(1)\n",
    "        gTrim = g[condition]\n",
    "\n",
    "        # insert the count of >0 columns\n",
    "        gTrim.insert(0, 'ngt0', gTrim.gt(0).sum(axis = 1))\n",
    "\n",
    "        # put the count back in\n",
    "        gTrim.insert(0, 'count', count[condition])\n",
    "\n",
    "\n",
    "\n",
    "        if (n == 0):\n",
    "            groupdf = gTrim\n",
    "        else:\n",
    "            groupdf = pd.concat([groupdf, gTrim])\n",
    "            \n",
    "        n += 1\n",
    "        \n",
    "    print(len(groupdf))\n",
    "        \n",
    "# for i,c in enumerate(useCols):\n",
    "#     g = usedf.groupby(useCols[i:]).size().reset_index().rename(columns = {0:'count'})\n",
    "    \n",
    "#     # add the missing column(s) as -1 (meaning could be anything)\n",
    "#     if (i > 0):\n",
    "#         for cc in useCols[:i]:\n",
    "#             g.insert(0, cc, -1)\n",
    "    \n",
    "#     # move the count column to the front\n",
    "#     count = g.pop('count')\n",
    "#     g.insert(0, 'count', count)\n",
    "\n",
    "#     if (i == 0):\n",
    "#         groupdf = g\n",
    "#     else:\n",
    "#         groupdf = pd.concat([groupdf, g])\n",
    "\n",
    "\n",
    "\n",
    "# take only the rows with > 5 people in the group\n",
    "groupdfTrim = groupdf.loc[groupdf['count'] > 5].reset_index(drop = True)\n",
    "\n",
    "# sort\n",
    "groupdfTrim.sort_values(by = 'count', ascending = False, inplace = True)\n",
    "\n",
    "groupdfTrim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531279a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for the checkbox answers, I only care about those that have multiple rows with values > 0\n",
    "# # so I will drop any of the groupdf rows that have only -1s and 0s with one non-zero value\n",
    "\n",
    "# # don't modify the original df\n",
    "# tmp = groupdf.copy()\n",
    "\n",
    "# # remove the count\n",
    "# count = tmp.pop('count')\n",
    "\n",
    "# # get the trim condition\n",
    "# condition = tmp.gt(0).sum(axis = 1).gt(1)\n",
    "# groupdfTrim = tmp[condition]\n",
    "\n",
    "# # insert the count of >0 columns\n",
    "# groupdfTrim.insert(0, 'ngt0', groupdfTrim.gt(0).sum(axis = 1))\n",
    "\n",
    "# # put the count back in\n",
    "# groupdfTrim.insert(0, 'count', count[condition])\n",
    "\n",
    "# # take only the rows with > 5 people in the group\n",
    "# groupdfTrim = groupdfTrim.loc[groupdfTrim['count'] > 5].reset_index(drop = True)\n",
    "\n",
    "# groupdfTrim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc256f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole_march22':roleMap,\n",
    "    'discipline_march22':disciplineMap,\n",
    "    'institution_march22':institutionMap,\n",
    "    'gender_march22':genderMap,\n",
    "    'firstgen0322':firstgenMap,\n",
    "    'army':armyMap\n",
    "}\n",
    "\n",
    "for key, value in insitutionTypeMap.items():\n",
    "    col = 'institution' + str(key)\n",
    "    replacements[col] = {1:value}\n",
    "    \n",
    "for key, value in raceMap2.items():\n",
    "    col = 'race_' + key + '_march22'\n",
    "    replacements[col] = {1:value}\n",
    "\n",
    "groupdfTrimHuman = groupdfTrim.replace(replacements)\n",
    "\n",
    "groupdfTrimHuman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b80c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print with human readable results\n",
    "counts = []\n",
    "groups = []\n",
    "for i,row in groupdfTrim.iterrows():\n",
    "    foo = row.copy()\n",
    "    foo.pop('count')\n",
    "    foo.pop('ngt0')\n",
    "    \n",
    "    bar = groupdfTrimHuman.iloc[i].copy()\n",
    "    bar.pop('count')\n",
    "    bar.pop('ngt0')\n",
    "    \n",
    "    # find the columns with values > 0\n",
    "    condition = foo.gt(0)\n",
    "    \n",
    "    counts.append(int(row['count']))\n",
    "    groups.append('; '.join(bar[condition].values))\n",
    "    \n",
    "    #print(f'{c:.0f} : {foo[condition].to_dict()}')\n",
    "\n",
    "# combine this into a dataframe so that I can easily drop the duplicates\n",
    "# (duplicates arise when I add a column to groupby and then it gets selected for a 0)\n",
    "outdf = pd.DataFrame({'count':counts, 'group':groups}).drop_duplicates(subset = 'group', keep = 'first')\n",
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8872a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.to_csv('data/demographicsGroups.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e106e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48ca828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f718624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988638d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556536a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e7e0602",
   "metadata": {},
   "source": [
    "## Scratch below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file does not have enough demographics info\n",
    "df = pd.read_spss('data/ParticipantProfile.sav')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff16e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.values\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18f83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like this data is included in the other file and not any more helpful to distinguish which questions is which\n",
    "df = pd.read_spss('data/Pre_Survey_Oct21.sav')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.values\n",
    "print(cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
