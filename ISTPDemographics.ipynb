{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434ba4ef",
   "metadata": {},
   "source": [
    "# ISTP demographics\n",
    "\n",
    "Data is from the ```ISTP Pro/Post Survey - Demographics (Vanessa)``` folder on Drive\n",
    "\n",
    "I will create files and tree plots.\n",
    "\n",
    "Running in the ```ete3``` conda environment (is WSL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65326f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fba69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree, faces, AttrFace, TreeStyle, TextFace, add_face_to_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64439bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDemographics(inputdf):\n",
    "\n",
    "    # loop through all the columns and groupby all the other columns to get the overlaps\n",
    "    # if i == 0, then we find the overlaps of all columns\n",
    "    # if i > 0, then we ignore any columns < i, and replace their values with nan\n",
    "    # using method from : https://stackoverflow.com/questions/35268817/unique-combinations-of-values-in-selected-columns-in-pandas-data-frame-and-count\n",
    "\n",
    "    n = 0\n",
    "    cols = inputdf.columns\n",
    "    for i in np.arange(1, len(cols)):\n",
    "        # get all the combinations of i columns in useCols\n",
    "        itr = list(itertools.combinations(cols, i))\n",
    "        print(i, len(itr))\n",
    "\n",
    "        # these columns will be used in groupby while others will be anything\n",
    "        for useColList in itr:\n",
    "            g = inputdf.groupby(list(useColList)).size().reset_index().rename(columns = {0:'count'})\n",
    "\n",
    "            # add the missing column(s) as NaN \n",
    "            for cc in cols:\n",
    "                if (cc not in useColList):\n",
    "                    g.insert(0, cc, np.nan)\n",
    "\n",
    "            # remove any rows that are all nans (excluding count)\n",
    "            g.dropna(how = 'all', inplace = True, subset = useColList)\n",
    "\n",
    "            # move the count column to be first\n",
    "            count = g.pop('count')\n",
    "            g.insert(0, 'count', count)\n",
    "\n",
    "            if (n == 0):\n",
    "                groupdf = g\n",
    "            else:\n",
    "                groupdf = pd.concat([groupdf, g])\n",
    "\n",
    "            n += 1\n",
    "\n",
    "        print(len(groupdf))\n",
    "\n",
    "    # convert any entry with a space or blank entry to nan\n",
    "    groupdf.replace(r'^\\s*$', np.nan, regex=True, inplace = True)\n",
    "\n",
    "    # remove duplicates\n",
    "    groupdf.drop_duplicates(keep = 'first', inplace = True)\n",
    "\n",
    "    # sort\n",
    "    groupdf = groupdf.sort_values(by = 'count', ascending = False)\n",
    "\n",
    "    # add a column that has the fraction of total\n",
    "    groupdf.insert(1, 'fraction', groupdf['count']/len(df))\n",
    "\n",
    "    # add a column to count the number of non-nan entries in each row (excluding \"count\" and \"fraction\")\n",
    "    groupdf.insert(2, 'nAxes', groupdf.count(axis = 1) - 2)\n",
    "\n",
    "    # remove any rows with nAxes == 0\n",
    "    groupdf = groupdf.loc[groupdf['nAxes'] > 0].reset_index(drop = True)\n",
    "\n",
    "    # take only the rows with > 5 people in the group and sort\n",
    "    groupdfTrim = groupdf.loc[groupdf['count'] > 5]\n",
    "    \n",
    "    # combine groups into a single columns, and output a condensed file\n",
    "    groups = []\n",
    "\n",
    "    for i,row in groupdf.iterrows():\n",
    "        foo = row[cols].copy().dropna().values\n",
    "\n",
    "        group = [x for x in foo if x != '' and not x.isspace()]\n",
    "        groups.append('; '.join(group))\n",
    "\n",
    "    outdf = groupdf[['count','fraction','nAxes']].copy()\n",
    "    outdf['group'] = groups\n",
    "    \n",
    "    return groupdf, groupdfTrim, outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiReplacer(inputdf, c, m):\n",
    "    # add a comma after everything to make the replacement easier\n",
    "    inputdf.loc[~pd.isna(inputdf[c]), c] = inputdf[c].loc[~pd.isna(inputdf[c])].astype(str) + ','    \n",
    "    \n",
    "    # can't use a simple string replace on the entire dataframe because there are single and double digits \n",
    "    # (e.g., 1, can be confused with 21,)\n",
    "    replacer = inputdf[c].values\n",
    "    for index,row in inputdf.iterrows():\n",
    "\n",
    "        if (row[c] is not np.nan):\n",
    "            replace = ''\n",
    "\n",
    "            if (',' in row[c]):\n",
    "                vals = list(filter(None, row[c].split(','))) # remove empty strings\n",
    "            else:\n",
    "                vals = [row[c]]\n",
    "\n",
    "            for v in vals: \n",
    "                try:\n",
    "                    if (v != ''):\n",
    "                        ind = int(float(v))\n",
    "                        val = m[ind]\n",
    "                        if (val is not np.nan):\n",
    "                            if (val not in replace):\n",
    "                                replace += val + ', '\n",
    "                except:\n",
    "                    replace = v\n",
    "                            \n",
    "            replacer[index] = replace\n",
    "            \n",
    "    replacer[np.where(pd.isna(replacer))] = 'Did not respond (' + c + ')'   \n",
    "     \n",
    "    return replacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef789f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsing categories (see demographicsBreakdown.ipynb for full categories)\n",
    "# I am going to ignore \"Other\" answers\n",
    "\n",
    "roleMap = {\n",
    "    1:'Faculty member, lecturer, instructor, or adjunct faculty',\n",
    "    2:'Graduate student or Postdoctoral scholar',\n",
    "    3:'Graduate student or Postdoctoral scholar',\n",
    "    4:'Staff member',\n",
    "    5:'Other (role)',\n",
    "    np.nan:'Did not respond (role)'\n",
    "\n",
    "}\n",
    "disciplineMap = {\n",
    "    1:'Agriculture and natural resource sciences',\n",
    "    2:'Arts',\n",
    "    3:'Biological and life sciences',\n",
    "    4:'Business and management science',\n",
    "    5:'Chemistry',\n",
    "    6:'Computer, information, and technological sciences',\n",
    "    7:'Earth, environmental, atmospheric, and ocean sciences',\n",
    "    8:'Education',\n",
    "    9:'Engineering',\n",
    "    10:'Humanities',\n",
    "    11:'Law',\n",
    "    12:'Mathematics and Statistics',\n",
    "    13:'Medical sciences',\n",
    "    14:'Physical sciences',\n",
    "    15:'Psychology',\n",
    "    16:'Social, behavioral, and economic sciences (not including psychology)',\n",
    "    17:'Other (discipline)',\n",
    "    np.nan:'Did not respond (discipline)'\n",
    "}\n",
    "disciplineSTEMMap = {\n",
    "    1:'STEM',\n",
    "    2:'non-STEM',\n",
    "    3:'STEM',\n",
    "    4:'non-STEM',\n",
    "    5:'STEM',\n",
    "    6:'STEM',\n",
    "    7:'STEM',\n",
    "    8:'non-STEM',\n",
    "    9:'STEM',\n",
    "    10:'non-STEM',\n",
    "    11:'non-STEM',\n",
    "    12:'STEM',\n",
    "    13:'non-STEM',\n",
    "    14:'STEM',\n",
    "    15:'STEM',\n",
    "    16:'STEM',\n",
    "    17:'Other (discipline)',\n",
    "    np.nan:'Did not respond (discipline)'\n",
    "}\n",
    "institutionMap = {\n",
    "    1:'Community college / 2-year institution',\n",
    "    7:'Comprehensive or Regional University',\n",
    "    8:'Liberal arts college',\n",
    "    9:'Research University',\n",
    "    10:'Technical college', \n",
    "    11:'Other (institution)',\n",
    "    np.nan:'Did not respond (institution)'\n",
    "\n",
    "}\n",
    "institutionMap_oct21 = {\n",
    "    1:'Community college / 2-year institution',\n",
    "    2:'Comprehensive or Regional University',\n",
    "    3:'Liberal arts college',\n",
    "    4:'Research University',\n",
    "    5:'Technical college', \n",
    "    6:'Other (institution)',\n",
    "    np.nan:'Did not respond (institution)'\n",
    "\n",
    "}\n",
    "genderMap = {\n",
    "    1:'Non-binary, gender queer, self-identify', \n",
    "    8:'Cis-Man/Trans-Man',\n",
    "    9:'Non-binary, gender queer, self-identify',\n",
    "    10:'Cis-Man/Trans-Man',\n",
    "    14:'Cis-Woman/Trans-Woman', \n",
    "    11:'Cis-Woman/Trans-Woman', \n",
    "    12:'Non-binary, gender queer, self-identify',\n",
    "    13:'I prefer not to respond (gender)',\n",
    "    np.nan:'Did not respond (gender)'\n",
    "}\n",
    "\n",
    "genderMap_oct21 = {\n",
    "    1:'Non-binary, gender queer, self-identify', \n",
    "    2:'Man',\n",
    "    3:'Non-binary, gender queer, self-identify',\n",
    "    4:'Transgender',\n",
    "    5:'Woman', \n",
    "    6:'Non-binary, gender queer, self-identify', \n",
    "    7:'I prefer not to respond (gender)',\n",
    "    np.nan:'Did not respond (gender)'\n",
    "}\n",
    "# these are checkboxes so I will keep each individual column\n",
    "institutionTypeMap = {\n",
    "    1:'Minority-focussed institution',\n",
    "    8:'Minority-focussed institution', \n",
    "    9:'Minority-focussed institution', \n",
    "    10:'Predominantly White Institution (PWI)',\n",
    "    11:'Minority-focussed institution',\n",
    "    12:'Minority-focussed institution',\n",
    "    13:'I am not sure (institution type)',\n",
    "    np.nan:'did not respond (institution type)'\n",
    "}\n",
    "raceMap = {\n",
    "    1:'Alaska Native, American Indian, Native American or Indigenous',\n",
    "    14:'Asian',\n",
    "    15:'Black or African American',\n",
    "    16:'Asian',\n",
    "    17:'Latina/o/x or Hispanic',\n",
    "    18:'other POC',\n",
    "    19:'other POC',\n",
    "    20:'Asian',\n",
    "    21:'Asian',\n",
    "    22:'White',\n",
    "    23:'Multiracial',\n",
    "    24:'I self-describe as (race)',\n",
    "    25:'I prefer not to respond (race)',\n",
    "    np.nan:'Did not respond (race)'\n",
    "\n",
    "}\n",
    "# not included in these files\n",
    "tenureMap = {\n",
    "    7:'Tenured and tenure-track',\n",
    "    19:'Tenured and tenure-track',\n",
    "    12:'Full-time teaching/instructional or research',\n",
    "    20:'Full-time teaching/instructional or research',\n",
    "    23:'Part-time teaching/instructional',\n",
    "    22:'Full-time teaching/instructional or research',\n",
    "    21:'Full-time teaching/instructional or research',\n",
    "    15:np.nan,\n",
    "    np.nan:'Did not respond (tenure)'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d3d06f",
   "metadata": {},
   "source": [
    "## First file\n",
    "```data/ISTP_demographics_spring22_Aaron.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ISTP_demographics_spring22_Aaron.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935df7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea694352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role, discipline, institution type, gender,  institution designation, race\n",
    "# (no faculty status in this file?),\n",
    "useCols = [\n",
    "    'primerole_march22', 'discipline_march22', 'institution_msi_oct22', \n",
    "    'gender_march22', 'institution_march22','race'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usedf = df[useCols]#.dropna(how = 'all').reset_index(drop = True)#.fillna(0)\n",
    "usedf = df.loc[df['completion_binary'] == 1][useCols].reset_index(drop = True)\n",
    "# add an additional column for STEM\n",
    "usedf['STEM_march22'] = usedf['discipline_march22']\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for indigenous (race == 1)\n",
    "col = usedf['race']\n",
    "foo = pd.DataFrame(col[col.str.contains('1').fillna(False)])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75da89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the entries\n",
    "\n",
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole_march22':roleMap,\n",
    "    'discipline_march22':disciplineMap,\n",
    "    'STEM_march22':disciplineSTEMMap,\n",
    "    'institution_march22':institutionMap,\n",
    "    'gender_march22':genderMap,\n",
    "#     'Q35.1':institutionTypeMap,\n",
    "#     'race':raceMap\n",
    "}\n",
    "\n",
    "usedfHuman = usedf.replace(replacements)\n",
    "\n",
    "# treat the cells with multiple entries a bit differently\n",
    "usedfHuman['institution_msi_oct22'] = multiReplacer(usedfHuman, 'institution_msi_oct22', institutionTypeMap)\n",
    "\n",
    "# for race we will put them in the 'Multiracial' category\n",
    "usedfHuman['race'].fillna('Did not respond (race)', inplace = True)\n",
    "usedfHuman.loc[usedfHuman['race'].str.contains(','), 'race'] = 'Multiracial' \n",
    "usedfHuman['race'] = multiReplacer(usedfHuman, 'race', raceMap)\n",
    "\n",
    "# remove any extra commas\n",
    "usedfHuman = usedfHuman.applymap(lambda x: str(x).rstrip(', '))\n",
    "\n",
    "# fix any lingering nan values\n",
    "usedfHuman.replace('nan',np.nan, inplace = True)\n",
    "usedfHuman.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "\n",
    "usedfHuman['primerole_march22'].fillna('Did not respond (role)', inplace = True)\n",
    "usedfHuman['discipline_march22'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['STEM_march22'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['institution_march22'].fillna('Did not respond (institution)', inplace = True)\n",
    "usedfHuman['gender_march22'].fillna('Did not respond (gender)', inplace = True)\n",
    "usedfHuman['institution_msi_oct22'].fillna('Did not respond (institution type)', inplace = True)\n",
    "# already filled race above\n",
    "\n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d433d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedfHuman.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cb6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedf.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d1e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdf, groupdfTrim, outdf = getDemographics(usedfHuman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28964fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdfTrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.to_csv(os.path.join('analysis','ISTP_demographics_march22_Aaron_demographicsGroupsCondensed.csv'), index = False)\n",
    "groupdf.to_csv(os.path.join('analysis','ISTP_demographics_march22_Aaron_demographicsGroupsFull.csv'), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a01bc42",
   "metadata": {},
   "source": [
    "## Make the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37236e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNodesToTree(base, cols, i, nodes, inputdf):\n",
    "    c = cols[i]\n",
    "    if (c in inputdf.columns):\n",
    "        # get the unique values in this column\n",
    "        unique_values = inputdf[c].dropna().unique()\n",
    "\n",
    "        # add them as nodes to the tree\n",
    "        for col_name in unique_values:\n",
    "            usedf = inputdf.loc[inputdf[c] == col_name]\n",
    "\n",
    "            # if there are >0 rows in the inputdf that have these values then \n",
    "            if len(usedf) > 0:\n",
    "                #name = ' ' + col_name + ' [' + str(len(usedf)) + '/' + str(len(inputdf)) + ', {:.1f}%] '.format(len(usedf)/len(inputdf)*100.)\n",
    "                name = ' ' + col_name + ' [' + str(len(usedf)) + ', {:.1f}%] '.format(len(usedf)/len(inputdf)*100.)\n",
    "                nodes[name] = base.add_child(name = name)\n",
    "                nodes[name].support = len(usedf)\n",
    "                \n",
    "                # recursively move down the tree\n",
    "                if (i+1 < len(cols)):\n",
    "                    addNodesToTree(nodes[name], cols, i+1, nodes, usedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/etetoolkit/ete/issues/219\n",
    "def my_layout(node):\n",
    "    F = TextFace(node.name, tight_text = True)\n",
    "    add_face_to_node(F, node, column = 0, position = \"branch-right\")\n",
    "        \n",
    "# http://etetoolkit.org/docs/latest/faqs/#how-do-i-visualize-internal-node-names\n",
    "# def my_layout(node):\n",
    "#     if node.is_leaf():\n",
    "#         # If terminal node, draws its name\n",
    "#         name_face = AttrFace(\"name\")\n",
    "#     else:\n",
    "#         # If internal node, draws label with smaller font size\n",
    "#         name_face = AttrFace(\"name\", fsize=10)\n",
    "#     # Adds the name face to the image at the preferred position\n",
    "#     faces.add_face_to_node(name_face, node, column=0, position=\"branch-right\")\n",
    "\n",
    "tree_style = TreeStyle()\n",
    "\n",
    "# Do not add leaf names automatically\n",
    "tree_style.show_leaf_name = False\n",
    "\n",
    "# increase the y spacing\n",
    "tree_style.branch_vertical_margin = 10\n",
    "\n",
    "# I need some way to remove the scale bar at the bottom\n",
    "\n",
    "# Use my custom layout\n",
    "tree_style.layout_fn = my_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8fc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSingleColTree(df, filename):\n",
    "    \n",
    "    # create the tree\n",
    "    tree = Tree()\n",
    "    nodes = {}\n",
    "    addNodesToTree(tree, df.columns, 0, nodes, df)\n",
    "    \n",
    "    # seems like to need to remove the file first or else it doesn't get written\n",
    "    fname = os.path.join(os.getcwd(),filename)\n",
    "    if os.path.isfile(fname):\n",
    "        os.remove(fname)\n",
    "    \n",
    "    # write the file\n",
    "    _ = tree.render(fname, w=11, units=\"in\", tree_style=tree_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSingleColTree(usedfHuman['gender_march22'].to_frame(), os.path.join('analysis','figures','ISTP_gender_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['race'].to_frame(), os.path.join('analysis','figures','ISTP_race_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['institution_march22'].to_frame(), os.path.join('analysis','figures','ISTP_institution_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['primerole_march22'].to_frame(), os.path.join('analysis','figures','ISTP_role_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['STEM_march22'].to_frame(), os.path.join('analysis','figures','ISTP_STEM_march22_tree.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fe9a5",
   "metadata": {},
   "source": [
    "## Second file\n",
    "```data/ISTP_demographics_fall21_Aaron.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ISTP_demographics_fall21_Aaron.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0edf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role, discipline, institution type, gender,  institution designation, race\n",
    "# (no faculty status in this file?),\n",
    "useCols = [\n",
    "    'primerole_oct21', 'discipline_oct21', 'institution_msi_oct21', \n",
    "    'gender_oct21', 'institution_oct21','race'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usedf = df[useCols]#.dropna(how = 'all').reset_index(drop = True)#.fillna(0)\n",
    "usedf = df.loc[df['completion_binary_oct21'] == 1][useCols].reset_index(drop = True)\n",
    "# add an additional column for STEM\n",
    "usedf['STEM_oct21'] = usedf['discipline_oct21']\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the entries\n",
    "\n",
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole_oct21':roleMap,\n",
    "    'discipline_oct21':disciplineMap,\n",
    "    'STEM_oct21':disciplineSTEMMap,\n",
    "    'institution_oct21':institutionMap_oct21,\n",
    "    'gender_oct21':genderMap_oct21,\n",
    "#     'Q35.1':institutionTypeMap,\n",
    "#     'race':raceMap\n",
    "}\n",
    "\n",
    "usedfHuman = usedf.replace(replacements)\n",
    "\n",
    "# treat the cells with multiple entries a bit differently\n",
    "usedfHuman['institution_msi_oct21'] = multiReplacer(usedfHuman, 'institution_msi_oct21', institutionTypeMap)\n",
    "\n",
    "# for race we will put them in the 'Multiracial' category\n",
    "usedfHuman['race'].fillna('Did not respond (race)', inplace = True)\n",
    "usedfHuman.loc[usedfHuman['race'].str.contains(','),'race'] = 'Multiracial' \n",
    "usedfHuman['race'] = multiReplacer(usedfHuman, 'race', raceMap)\n",
    "\n",
    "# remove any extra commas\n",
    "usedfHuman = usedfHuman.applymap(lambda x: str(x).rstrip(', '))\n",
    "\n",
    "# fix any lingering nan values\n",
    "usedfHuman.replace('nan',np.nan, inplace = True)\n",
    "usedfHuman.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "\n",
    "usedfHuman['primerole_oct21'].fillna('Did not respond (role)', inplace = True)\n",
    "usedfHuman['discipline_oct21'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['STEM_oct21'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['institution_oct21'].fillna('Did not respond (institution)', inplace = True)\n",
    "usedfHuman['gender_oct21'].fillna('Did not respond (gender)', inplace = True)\n",
    "usedfHuman['institution_msi_oct21'].fillna('Did not respond (institution type)', inplace = True)\n",
    "# already filled race above\n",
    "\n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdf, groupdfTrim, outdf = getDemographics(usedfHuman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66977090",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdfTrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0269845",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.to_csv(os.path.join('analysis','ISTP_demographics_oct21_Aaron_demographicsGroupsCondensed.csv'), index = False)\n",
    "groupdf.to_csv(os.path.join('analysis','ISTP_demographics_oct21_Aaron_demographicsGroupsFull.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSingleColTree(usedfHuman['gender_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_gender_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['race'].to_frame(), os.path.join('analysis','figures','ISTP_race_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['institution_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_institution_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['primerole_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_role_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['STEM_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_STEM_oct21_tree.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeac0843",
   "metadata": {},
   "source": [
    "## Create an input data file for the bundling vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae1a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundling = []\n",
    "\n",
    "cols1 = ['primerole_oct21','institution_oct21','gender_oct21','race','count']\n",
    "bundlingDf = groupdfTrim[cols1].copy()\n",
    "#bundlingDf = bundlingDf[bundlingDf.isnull().sum(axis=1) <= 2]\n",
    "\n",
    "# cols1 = ['primerole_oct21','institution_oct21','gender_oct21','race']\n",
    "# bundlingDf = usedfHuman[cols1].copy()\n",
    "# bundlingDf['count'] = 1.\n",
    "\n",
    "bundlingDf.rename(columns = {'primerole_oct21':'Role',\n",
    "                   'institution_oct21':'Institution Type',\n",
    "                  'gender_oct21':'Gender',\n",
    "                  'race':'Race'}, inplace = True)\n",
    "cols = ['Role', 'Institution Type', 'Gender', 'Race']\n",
    "\n",
    "# do I need to expand this to have multiple rows per person, one for each demographic category?\n",
    "# try with just the first 2 rows\n",
    "\n",
    "for i, row in bundlingDf.iterrows():\n",
    "    demo_dict = row[cols].to_dict()\n",
    "    demo_list = []\n",
    "    for key in demo_dict.keys():\n",
    "        if (not pd.isnull(demo_dict[key])):\n",
    "            demo_list.append(key + '.' + demo_dict[key])\n",
    "#     demo_list = [key + '.' + demo_dict[key] if not math.isnan(demo_dict[key]) for key in demo_dict.keys()]\n",
    "    for c in cols:\n",
    "        if (not pd.isnull(row[c])):\n",
    "            person = 'person' + str(i).zfill(3)\n",
    "            demo = c + '.' + row[c]\n",
    "            other_demo_list = demo_list.copy()\n",
    "            other_demo_list.remove(demo)\n",
    "\n",
    "            entry = {'name':demo + '.' + person, \n",
    "                     'other_demographics':[ v + '.' + person for v in other_demo_list], \n",
    "    #                  'full_demographics':', '.join(list(demo_dict.values()))\n",
    "                     'size': row['count']\n",
    "                    }\n",
    "            bundling.append(entry)\n",
    "#     if (i > 2):\n",
    "#         break\n",
    "        \n",
    "#bundling\n",
    "    \n",
    "    \n",
    "# I need to combine duplicates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782436ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('demographics_circle_bundling_plot', 'src','data','ISTP_demographics_oct21_bundling.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(bundling)\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundlingDf['Gender'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270ee1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
