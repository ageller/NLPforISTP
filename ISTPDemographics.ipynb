{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "434ba4ef",
   "metadata": {},
   "source": [
    "# ISTP demographics\n",
    "\n",
    "Data is from the ```ISTP Pro/Post Survey - Demographics (Vanessa)``` folder on Drive\n",
    "\n",
    "I will create files and tree plots.\n",
    "\n",
    "Running in the ```ete3``` conda environment (is WSL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65326f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "import json\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fba69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ete3 import Tree, faces, AttrFace, TreeStyle, TextFace, add_face_to_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64439bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4f1c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDemographics(inputdf):\n",
    "\n",
    "    # loop through all the columns and groupby all the other columns to get the overlaps\n",
    "    # if i == 0, then we find the overlaps of all columns\n",
    "    # if i > 0, then we ignore any columns < i, and replace their values with nan\n",
    "    # using method from : https://stackoverflow.com/questions/35268817/unique-combinations-of-values-in-selected-columns-in-pandas-data-frame-and-count\n",
    "\n",
    "    n = 0\n",
    "    cols = inputdf.columns\n",
    "    for i in np.arange(1, len(cols)):\n",
    "        # get all the combinations of i columns in useCols\n",
    "        itr = list(itertools.combinations(cols, i))\n",
    "        print(i, len(itr))\n",
    "\n",
    "        # these columns will be used in groupby while others will be anything\n",
    "        for useColList in itr:\n",
    "            g = inputdf.groupby(list(useColList)).size().reset_index().rename(columns = {0:'count'})\n",
    "\n",
    "            # add the missing column(s) as NaN \n",
    "            for cc in cols:\n",
    "                if (cc not in useColList):\n",
    "                    g.insert(0, cc, np.nan)\n",
    "\n",
    "            # remove any rows that are all nans (excluding count)\n",
    "            g.dropna(how = 'all', inplace = True, subset = useColList)\n",
    "\n",
    "            # move the count column to be first\n",
    "            count = g.pop('count')\n",
    "            g.insert(0, 'count', count)\n",
    "\n",
    "            if (n == 0):\n",
    "                groupdf = g\n",
    "            else:\n",
    "                groupdf = pd.concat([groupdf, g])\n",
    "\n",
    "            n += 1\n",
    "\n",
    "        print(len(groupdf))\n",
    "\n",
    "    # convert any entry with a space or blank entry to nan\n",
    "    groupdf.replace(r'^\\s*$', np.nan, regex=True, inplace = True)\n",
    "\n",
    "    # remove duplicates\n",
    "    groupdf.drop_duplicates(keep = 'first', inplace = True)\n",
    "\n",
    "    # sort\n",
    "    groupdf = groupdf.sort_values(by = 'count', ascending = False)\n",
    "\n",
    "    # add a column that has the fraction of total\n",
    "    groupdf.insert(1, 'fraction', groupdf['count']/len(df))\n",
    "\n",
    "    # add a column to count the number of non-nan entries in each row (excluding \"count\" and \"fraction\")\n",
    "    groupdf.insert(2, 'nAxes', groupdf.count(axis = 1) - 2)\n",
    "\n",
    "    # remove any rows with nAxes == 0\n",
    "    groupdf = groupdf.loc[groupdf['nAxes'] > 0].reset_index(drop = True)\n",
    "\n",
    "    # take only the rows with > 5 people in the group and sort\n",
    "    groupdfTrim = groupdf.loc[groupdf['count'] > 5]\n",
    "    \n",
    "    # combine groups into a single columns, and output a condensed file\n",
    "    groups = []\n",
    "\n",
    "    for i,row in groupdf.iterrows():\n",
    "        foo = row[cols].copy().dropna().values\n",
    "\n",
    "        group = [x for x in foo if x != '' and not x.isspace()]\n",
    "        groups.append('; '.join(group))\n",
    "\n",
    "    outdf = groupdf[['count','fraction','nAxes']].copy()\n",
    "    outdf['group'] = groups\n",
    "    \n",
    "    return groupdf, groupdfTrim, outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d96be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiReplacer(inputdf, c, m):\n",
    "    # add a comma after everything to make the replacement easier\n",
    "    inputdf.loc[~pd.isna(inputdf[c]), c] = inputdf[c].loc[~pd.isna(inputdf[c])].astype(str) + ','    \n",
    "    \n",
    "    # can't use a simple string replace on the entire dataframe because there are single and double digits \n",
    "    # (e.g., 1, can be confused with 21,)\n",
    "    replacer = inputdf[c].values\n",
    "    for index,row in inputdf.iterrows():\n",
    "\n",
    "        if (row[c] is not np.nan):\n",
    "            replace = ''\n",
    "\n",
    "            if (',' in row[c]):\n",
    "                vals = list(filter(None, row[c].split(','))) # remove empty strings\n",
    "            else:\n",
    "                vals = [row[c]]\n",
    "\n",
    "            for v in vals: \n",
    "                try:\n",
    "                    if (v != ''):\n",
    "                        ind = int(float(v))\n",
    "                        val = m[ind]\n",
    "                        if (val is not np.nan):\n",
    "                            if (val not in replace):\n",
    "                                replace += val + ', '\n",
    "                except:\n",
    "                    replace = v\n",
    "                            \n",
    "            replacer[index] = replace\n",
    "            \n",
    "    replacer[np.where(pd.isna(replacer))] = 'Did not respond (' + c + ')'   \n",
    "     \n",
    "    return replacer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8250a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNodeFractions(inputdf):\n",
    "    # assume that this df has only 1 column\n",
    "    col = inputdf.columns[0]\n",
    "    unique_values = inputdf[col].dropna().unique()\n",
    "    count = np.zeros_like(unique_values)\n",
    "    for i,name in enumerate(unique_values):\n",
    "        foo = inputdf.loc[inputdf[col] == name]\n",
    "        count[i] = len(foo)\n",
    "\n",
    "    outdf = pd.DataFrame()\n",
    "    outdf[col] = unique_values\n",
    "    outdf['count'] = count\n",
    "    outdf['fraction'] = np.array(count)/len(inputdf)\n",
    "    # add error\n",
    "    \n",
    "    return outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37236e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNodesToTree(base, cols, i, nodes, inputdf):\n",
    "    c = cols[i]\n",
    "    if (c in inputdf.columns):\n",
    "        # get the unique values in this column\n",
    "        unique_values = inputdf[c].dropna().unique()\n",
    "\n",
    "        # add them as nodes to the tree\n",
    "        for col_name in unique_values:\n",
    "            usedf = inputdf.loc[inputdf[c] == col_name]\n",
    "\n",
    "            # if there are >0 rows in the inputdf that have these values then \n",
    "            if len(usedf) > 0:\n",
    "                #name = ' ' + col_name + ' [' + str(len(usedf)) + '/' + str(len(inputdf)) + ', {:.1f}%] '.format(len(usedf)/len(inputdf)*100.)\n",
    "                name = ' ' + col_name + ' [' + str(len(usedf)) + ', {:.1f}%] '.format(len(usedf)/len(inputdf)*100.)\n",
    "                nodes[name] = base.add_child(name = name)\n",
    "                nodes[name].support = len(usedf)\n",
    "                \n",
    "                # recursively move down the tree\n",
    "                if (i+1 < len(cols)):\n",
    "                    addNodesToTree(nodes[name], cols, i+1, nodes, usedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276f3842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/etetoolkit/ete/issues/219\n",
    "def my_tree_layout(node):\n",
    "    F = TextFace(node.name, tight_text = True)\n",
    "    add_face_to_node(F, node, column = 0, position = \"branch-right\")\n",
    "        \n",
    "# http://etetoolkit.org/docs/latest/faqs/#how-do-i-visualize-internal-node-names\n",
    "# def my_layout(node):\n",
    "#     if node.is_leaf():\n",
    "#         # If terminal node, draws its name\n",
    "#         name_face = AttrFace(\"name\")\n",
    "#     else:\n",
    "#         # If internal node, draws label with smaller font size\n",
    "#         name_face = AttrFace(\"name\", fsize=10)\n",
    "#     # Adds the name face to the image at the preferred position\n",
    "#     faces.add_face_to_node(name_face, node, column=0, position=\"branch-right\")\n",
    "\n",
    "tree_style = TreeStyle()\n",
    "\n",
    "# Do not add leaf names automatically\n",
    "tree_style.show_leaf_name = False\n",
    "\n",
    "# increase the y spacing\n",
    "tree_style.branch_vertical_margin = 10\n",
    "\n",
    "# I need some way to remove the scale bar at the bottom\n",
    "\n",
    "# Use my custom layout\n",
    "tree_style.layout_fn = my_tree_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8fc695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSingleColTree(df, filename):\n",
    "    \n",
    "    # create the tree\n",
    "    tree = Tree()\n",
    "    nodes = {}\n",
    "    addNodesToTree(tree, df.columns, 0, nodes, df)\n",
    "    \n",
    "    # seems like to need to remove the file first or else it doesn't get written\n",
    "    fname = os.path.join(os.getcwd(),filename)\n",
    "    if os.path.isfile(fname):\n",
    "        os.remove(fname)\n",
    "    \n",
    "    # write the file\n",
    "    _ = tree.render(fname, w=11, units=\"in\", tree_style=tree_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileCircleData(df):\n",
    "    # create a tmp df and an out df\n",
    "    tmpDf = df.copy()\n",
    "    cols = df.columns\n",
    "    outDf = pd.DataFrame(columns = cols)\n",
    "    \n",
    "    count = []\n",
    "    \n",
    "    cnt = 0\n",
    "    #while (len(tmpDf) > 0 and cnt < 1000):\n",
    "    while (len(tmpDf) > 0 ):\n",
    "        # take the first row in the df\n",
    "        row = tmpDf.iloc[0]\n",
    "        \n",
    "        # check for any with matching demographics\n",
    "        foo = tmpDf.copy()\n",
    "        for c in cols:\n",
    "            foo = foo.loc[foo[c] == row[c]]\n",
    "            \n",
    "        # count them, add then to outDf and remove them from tmpDf\n",
    "        count.append(len(foo))\n",
    "        outDf = outDf.append(row)\n",
    "        tmpDf = tmpDf.drop(index = foo.index)#.reset_index(drop = True)\n",
    "        cnt += 1\n",
    "        #print(cnt, len(tmpDf), row)\n",
    "        \n",
    "    outDf['count'] = count\n",
    "    \n",
    "    return outDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dac587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCircleInput(circleDf, cols):\n",
    "    circle = []\n",
    "    # do I need to expand this to have multiple rows per person, one for each demographic category?\n",
    "\n",
    "    for i, row in circleDf.iterrows():\n",
    "        demo_dict = row[cols].to_dict()\n",
    "        demo_list = []\n",
    "        for key in demo_dict.keys():\n",
    "            if (not pd.isnull(demo_dict[key])):\n",
    "                demo_list.append(key + '.' + demo_dict[key])\n",
    "    #     demo_list = [key + '.' + demo_dict[key] if not math.isnan(demo_dict[key]) for key in demo_dict.keys()]\n",
    "        done = False\n",
    "        for c in cols:\n",
    "            #if (not pd.isnull(row[c])):\n",
    "            # just take one entry per \"person\"\n",
    "            if (not pd.isnull(row[c]) and not done):\n",
    "                done = True\n",
    "                person = 'person' + str(i).zfill(3)\n",
    "                demo = c + '.' + row[c]\n",
    "                other_demo_list = demo_list.copy()\n",
    "                other_demo_list.remove(demo)\n",
    "\n",
    "                entry = {'name':demo + '.' + person, \n",
    "                         'other_demographics':[ v + '.' + person for v in other_demo_list], \n",
    "                         'full_demographics':other_demo_list + [demo],\n",
    "                         'size': row['count']\n",
    "                        }\n",
    "                circle.append(entry)\n",
    "                \n",
    "    return circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_contingency(usedf, key, d1, d2, i):\n",
    "    col = ['date',usedf[key].iloc[i], 'not_' + usedf[key].iloc[i], 'total']\n",
    "    contingency = pd.DataFrame(columns = col)\n",
    "    contingency[col[0]] = [d1, d2, 'total']\n",
    "    contingency[col[1]] = [usedf.iloc[i]['count_' + d1], \n",
    "                           usedf.iloc[i]['count_' + d2], \n",
    "                           usedf.iloc[i]['count_' + d1] + usedf.iloc[i]['count_' + d2]]\n",
    "    contingency[col[2]] = [np.sum(usedf['count_' + d1]) - usedf.iloc[i]['count_' + d1], \n",
    "                           np.sum(usedf['count_' + d2]) - usedf.iloc[i]['count_' + d2], \n",
    "                           np.sum(usedf['count_' + d1]) - usedf.iloc[i]['count_' + d1] + \n",
    "                           np.sum(usedf['count_' + d2]) - usedf.iloc[i]['count_' + d2]]\n",
    "    contingency[col[3]] = contingency[col[1]] + contingency[col[2]]\n",
    "    contingency.set_index('date', drop = True, inplace = True)\n",
    "    \n",
    "    return contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef789f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapsing categories (see demographicsBreakdown.ipynb for full categories)\n",
    "# I am going to ignore \"Other\" answers\n",
    "\n",
    "roleMap = {\n",
    "    1:'Faculty member, lecturer, instructor, or adjunct faculty',\n",
    "    2:'Graduate student or Postdoctoral scholar',\n",
    "    3:'Graduate student or Postdoctoral scholar',\n",
    "    4:'Staff member',\n",
    "    5:'Other (role)',\n",
    "    np.nan:'Did not respond (role)'\n",
    "\n",
    "}\n",
    "disciplineMap = {\n",
    "    1:'Agriculture and natural resource sciences',\n",
    "    2:'Arts',\n",
    "    3:'Biological and life sciences',\n",
    "    4:'Business and management science',\n",
    "    5:'Chemistry',\n",
    "    6:'Computer, information, and technological sciences',\n",
    "    7:'Earth, environmental, atmospheric, and ocean sciences',\n",
    "    8:'Education',\n",
    "    9:'Engineering',\n",
    "    10:'Humanities',\n",
    "    11:'Law',\n",
    "    12:'Mathematics and Statistics',\n",
    "    13:'Medical sciences',\n",
    "    14:'Physical sciences',\n",
    "    15:'Psychology',\n",
    "    16:'Social, behavioral, and economic sciences (not including psychology)',\n",
    "    17:'Other (discipline)',\n",
    "    np.nan:'Did not respond (discipline)'\n",
    "}\n",
    "disciplineSTEMMap = {\n",
    "    1:'STEM',\n",
    "    2:'non-STEM',\n",
    "    3:'STEM',\n",
    "    4:'non-STEM',\n",
    "    5:'STEM',\n",
    "    6:'STEM',\n",
    "    7:'STEM',\n",
    "    8:'non-STEM',\n",
    "    9:'STEM',\n",
    "    10:'non-STEM',\n",
    "    11:'non-STEM',\n",
    "    12:'STEM',\n",
    "#    13:'non-STEM',\n",
    "    13:'Medical sciences',\n",
    "    14:'STEM',\n",
    "    15:'STEM',\n",
    "    16:'STEM',\n",
    "    17:'Other (discipline)',\n",
    "    np.nan:'Did not respond (discipline)'\n",
    "}\n",
    "institutionMap = {\n",
    "    1:'Community college / 2-year institution',\n",
    "    7:'Comprehensive or Regional University',\n",
    "    8:'Liberal arts college',\n",
    "    9:'Research University',\n",
    "    10:'Technical college', \n",
    "    11:'Other (institution)',\n",
    "    np.nan:'Did not respond (institution)'\n",
    "\n",
    "}\n",
    "institutionMap_oct21 = {\n",
    "    1:'Community college / 2-year institution',\n",
    "    2:'Comprehensive or Regional University',\n",
    "    3:'Liberal arts college',\n",
    "    4:'Research University',\n",
    "    5:'Technical college', \n",
    "    6:'Other (institution)',\n",
    "    np.nan:'Did not respond (institution)'\n",
    "\n",
    "}\n",
    "# genderMap = {\n",
    "#     1:'Non-binary, gender queer, self-identify', \n",
    "#     8:'Cis-Man/Trans-Man',\n",
    "#     9:'Non-binary, gender queer, self-identify',\n",
    "#     10:'Cis-Man/Trans-Man',\n",
    "#     14:'Cis-Woman/Trans-Woman', \n",
    "#     11:'Cis-Woman/Trans-Woman', \n",
    "#     12:'Non-binary, gender queer, self-identify',\n",
    "#     13:'I prefer not to respond (gender)',\n",
    "#     np.nan:'Did not respond (gender)'\n",
    "# }\n",
    "    \n",
    "genderMap = {\n",
    "    1:'Non-binary, gender queer, self-identify', \n",
    "    8:'Man',\n",
    "    9:'Non-binary, gender queer, self-identify',\n",
    "    10:'Transgender',\n",
    "    11:'Woman', \n",
    "    12:'Non-binary, gender queer, self-identify', \n",
    "    13:'I prefer not to respond (gender)',\n",
    "    14:'Transgender', \n",
    "    np.nan:'Did not respond (gender)'\n",
    "}\n",
    "    \n",
    "genderMap_oct21 = {\n",
    "    1:'Non-binary, gender queer, self-identify', \n",
    "    2:'Man',\n",
    "    3:'Non-binary, gender queer, self-identify',\n",
    "    4:'Transgender',\n",
    "    5:'Woman', \n",
    "    6:'Non-binary, gender queer, self-identify', \n",
    "    7:'I prefer not to respond (gender)',\n",
    "    np.nan:'Did not respond (gender)'\n",
    "}\n",
    "\n",
    "genderMap_prefall22 = {\n",
    "    1:'Non-binary, gender queer, self-identify', \n",
    "    2:'Man',\n",
    "    3:'Non-binary, gender queer, self-identify',\n",
    "    4:'Transgender',\n",
    "    5:'Transgender', \n",
    "    6:'Woman', \n",
    "    7:'Non-binary, gender queer, self-identify',\n",
    "    8:'I prefer not to respond (gender)',\n",
    "    np.nan:'Did not respond (gender)'\n",
    "}\n",
    "# these are checkboxes so I will keep each individual column\n",
    "institutionTypeMap = {\n",
    "    1:'Minority-focussed institution',\n",
    "    8:'Minority-focussed institution', \n",
    "    9:'Minority-focussed institution', \n",
    "    10:'Predominantly White Institution (PWI)',\n",
    "    11:'Minority-focussed institution',\n",
    "    12:'Minority-focussed institution',\n",
    "    13:'I am not sure (institution type)',\n",
    "    np.nan:'did not respond (institution type)'\n",
    "}\n",
    "raceMap = {\n",
    "    1:'Alaska Native, American Indian, Native American or Indigenous',\n",
    "    14:'Asian',\n",
    "    15:'Black or African American',\n",
    "    16:'Asian',\n",
    "    17:'Latina/o/x or Hispanic',\n",
    "    18:'other POC',\n",
    "    19:'other POC',\n",
    "    20:'Asian',\n",
    "    21:'Asian',\n",
    "    22:'White',\n",
    "    23:'Multiracial',\n",
    "    24:'I self-describe as (race)',\n",
    "    25:'I prefer not to respond (race)',\n",
    "    np.nan:'Did not respond (race)'\n",
    "}\n",
    "raceMap_prefall22 = {\n",
    "    1:'Alaska Native, American Indian, Native American or Indigenous',\n",
    "    2:'Asian',\n",
    "    3:'Black or African American',\n",
    "    4:'Asian',\n",
    "    5:'Latina/o/x or Hispanic',\n",
    "    6:'other POC',\n",
    "    7:'other POC',\n",
    "    8:'Asian',\n",
    "    9:'Asian',\n",
    "    10:'White',\n",
    "    11:'Multiracial',\n",
    "    12:'I self-describe as (race)',\n",
    "    13:'I prefer not to respond (race)',\n",
    "    np.nan:'Did not respond (race)'\n",
    "}\n",
    "# not included in these files\n",
    "tenureMap = {\n",
    "    7:'Tenured and tenure-track',\n",
    "    19:'Tenured and tenure-track',\n",
    "    12:'Full-time teaching/instructional or research',\n",
    "    20:'Full-time teaching/instructional or research',\n",
    "    23:'Part-time teaching/instructional',\n",
    "    22:'Full-time teaching/instructional or research',\n",
    "    21:'Full-time teaching/instructional or research',\n",
    "    15:np.nan,\n",
    "    np.nan:'Did not respond (tenure)'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d3d06f",
   "metadata": {},
   "source": [
    "## First file\n",
    "```data/ISTP_demographics_spring22_Aaron.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ISTP_demographics_spring22_Aaron.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935df7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea694352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role, discipline, institution type, gender,  institution designation, race\n",
    "# (no faculty status in this file?),\n",
    "useCols = [\n",
    "    'primerole_march22', 'discipline_march22', 'institution_msi_oct22', \n",
    "    'gender_march22', 'institution_march22','race'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f1c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usedf = df[useCols]#.dropna(how = 'all').reset_index(drop = True)#.fillna(0)\n",
    "usedf = df.loc[df['completion_binary'] == 1][useCols].reset_index(drop = True)\n",
    "# add an additional column for STEM\n",
    "usedf['STEM_march22'] = usedf['discipline_march22']\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3b89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for indigenous (race == 1)\n",
    "col = usedf['race']\n",
    "foo = pd.DataFrame(col[col.str.contains('1').fillna(False)])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedf['primerole_march22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75da89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the NaN values in all the columns\n",
    "Nnan = []\n",
    "for c in useCols:\n",
    "    N1 = usedf[c].isna().sum().sum()\n",
    "    try:\n",
    "        N2 = len(usedf[usedf[c].str.contains('nan')])\n",
    "    except:\n",
    "         N2 = 0\n",
    "    try:\n",
    "        N3 = len(usedf[usedf[c].str.contains(r'^\\s*$', regex = True)])\n",
    "    except:\n",
    "        N3 = 0\n",
    "        \n",
    "    Nnan.append(N1 + N2 + N3)\n",
    "    print(f'# NaN in {c} = {N1 + N2 + N3}')\n",
    "print('')\n",
    "\n",
    "# replace the entries\n",
    "\n",
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole_march22':roleMap,\n",
    "    'discipline_march22':disciplineMap,\n",
    "    'STEM_march22':disciplineSTEMMap,\n",
    "    'institution_march22':institutionMap,\n",
    "    'gender_march22':genderMap,\n",
    "#     'Q35.1':institutionTypeMap,\n",
    "#     'race':raceMap\n",
    "}\n",
    "\n",
    "usedfHuman = usedf.replace(replacements)\n",
    "\n",
    "\n",
    "# treat the cells with multiple entries a bit differently\n",
    "usedfHuman['institution_msi_oct22'] = multiReplacer(usedfHuman, 'institution_msi_oct22', institutionTypeMap)\n",
    "\n",
    "# for race we will put them in the 'Multiracial' category\n",
    "usedfHuman['race'].fillna('Did not respond (race)', inplace = True)\n",
    "foo = usedfHuman.loc[usedfHuman['race'].str.contains(',')]\n",
    "print('number of people with multiple race entries = ', len(foo))\n",
    "usedfHuman.loc[usedfHuman['race'].str.contains(','), 'race'] = 'Multiracial' \n",
    "usedfHuman['race'] = multiReplacer(usedfHuman, 'race', raceMap)\n",
    "\n",
    "# remove any extra commas\n",
    "usedfHuman = usedfHuman.applymap(lambda x: str(x).rstrip(', '))\n",
    "\n",
    "# fix any lingering nan values\n",
    "usedfHuman.replace('nan',np.nan, inplace = True)\n",
    "usedfHuman.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "\n",
    "usedfHuman['primerole_march22'].fillna('Did not respond (role)', inplace = True)\n",
    "usedfHuman['discipline_march22'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['STEM_march22'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['institution_march22'].fillna('Did not respond (institution)', inplace = True)\n",
    "usedfHuman['gender_march22'].fillna('Did not respond (gender)', inplace = True)\n",
    "usedfHuman['institution_msi_oct22'].fillna('Did not respond (institution type)', inplace = True)\n",
    "# already filled race above\n",
    "\n",
    "\n",
    "# print number of people with did not respond values in all the columns\n",
    "print('')\n",
    "for i, c in enumerate(useCols):\n",
    "    N1 = len(usedfHuman[usedfHuman[c].str.contains('respond')])\n",
    "    print(f'# marked \"prefer not to respond\" {c} = {N1 - Nnan[i]}')\n",
    "    \n",
    "    \n",
    "usedfHuman_march22 = usedfHuman\n",
    "\n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d433d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedfHuman.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5cb6d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "usedf.iloc[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29d1e2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupdf, groupdfTrim, outdf = getDemographics(usedfHuman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28964fcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupdfTrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e4d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.to_csv(os.path.join('analysis','ISTP_demographics_march22_Aaron_demographicsGroupsCondensed.csv'), index = False)\n",
    "groupdf.to_csv(os.path.join('analysis','ISTP_demographics_march22_Aaron_demographicsGroupsFull.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSingleColTree(usedfHuman['gender_march22'].to_frame(), os.path.join('analysis','figures','ISTP_gender_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['race'].to_frame(), os.path.join('analysis','figures','ISTP_race_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['institution_march22'].to_frame(), os.path.join('analysis','figures','ISTP_institution_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['primerole_march22'].to_frame(), os.path.join('analysis','figures','ISTP_role_march22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['STEM_march22'].to_frame(), os.path.join('analysis','figures','ISTP_STEMmed_march22_tree.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fe9a5",
   "metadata": {},
   "source": [
    "## Second file\n",
    "```data/ISTP_demographics_fall21_Aaron.csv```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/ISTP_demographics_fall21_Aaron.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0edf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e86fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role, discipline, institution type, gender,  institution designation, race\n",
    "# (no faculty status in this file?),\n",
    "useCols = [\n",
    "    'primerole_oct21', 'discipline_oct21', 'institution_msi_oct21', \n",
    "    'gender_oct21', 'institution_oct21','race'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usedf = df[useCols]#.dropna(how = 'all').reset_index(drop = True)#.fillna(0)\n",
    "usedf = df.loc[df['completion_binary_oct21'] == 1][useCols].reset_index(drop = True)\n",
    "# add an additional column for STEM\n",
    "usedf['STEM_oct21'] = usedf['discipline_oct21']\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60de4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the NaN values in all the columns\n",
    "Nnan = []\n",
    "for c in useCols:\n",
    "    N1 = usedf[c].isna().sum().sum()\n",
    "    try:\n",
    "        N2 = len(usedf[usedf[c].str.contains('nan')])\n",
    "    except:\n",
    "         N2 = 0\n",
    "    try:\n",
    "        N3 = len(usedf[usedf[c].str.contains(r'^\\s*$', regex = True)])\n",
    "    except:\n",
    "        N3 = 0\n",
    "        \n",
    "    Nnan.append(N1 + N2 + N3)\n",
    "    print(f'# NaN in {c} = {N1 + N2 + N3}')\n",
    "print('')\n",
    "\n",
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole_oct21':roleMap,\n",
    "    'discipline_oct21':disciplineMap,\n",
    "    'STEM_oct21':disciplineSTEMMap,\n",
    "    'institution_oct21':institutionMap_oct21,\n",
    "    'gender_oct21':genderMap_oct21,\n",
    "#     'Q35.1':institutionTypeMap,\n",
    "#     'race':raceMap\n",
    "}\n",
    "\n",
    "usedfHuman = usedf.replace(replacements)\n",
    "\n",
    "# treat the cells with multiple entries a bit differently\n",
    "usedfHuman['institution_msi_oct21'] = multiReplacer(usedfHuman, 'institution_msi_oct21', institutionTypeMap)\n",
    "\n",
    "# for race we will put them in the 'Multiracial' category\n",
    "usedfHuman['race'].fillna('Did not respond (race)', inplace = True)\n",
    "foo = usedfHuman.loc[usedfHuman['race'].str.contains(',')]\n",
    "print('number of people with multiple race entries = ', len(foo))\n",
    "usedfHuman.loc[usedfHuman['race'].str.contains(','),'race'] = 'Multiracial' \n",
    "usedfHuman['race'] = multiReplacer(usedfHuman, 'race', raceMap)\n",
    "\n",
    "# remove any extra commas\n",
    "usedfHuman = usedfHuman.applymap(lambda x: str(x).rstrip(', '))\n",
    "\n",
    "# fix any lingering nan values\n",
    "usedfHuman.replace('nan',np.nan, inplace = True)\n",
    "usedfHuman.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "\n",
    "usedfHuman['primerole_oct21'].fillna('Did not respond (role)', inplace = True)\n",
    "usedfHuman['discipline_oct21'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['STEM_oct21'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['institution_oct21'].fillna('Did not respond (institution)', inplace = True)\n",
    "usedfHuman['gender_oct21'].fillna('Did not respond (gender)', inplace = True)\n",
    "usedfHuman['institution_msi_oct21'].fillna('Did not respond (institution type)', inplace = True)\n",
    "# already filled race above\n",
    "\n",
    "# print number of people with did not respond values in all the columns\n",
    "print('')\n",
    "for i, c in enumerate(useCols):\n",
    "    N1 = len(usedfHuman[usedfHuman[c].str.contains('respond')])\n",
    "    print(f'# marked \"prefer not to respond\" {c} = {N1 - Nnan[i]}')\n",
    "usedfHuman_oct21 = usedfHuman\n",
    "\n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdf, groupdfTrim, outdf = getDemographics(usedfHuman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66977090",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupdfTrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a5a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0269845",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.to_csv(os.path.join('analysis','ISTP_demographics_oct21_Aaron_demographicsGroupsCondensed.csv'), index = False)\n",
    "groupdf.to_csv(os.path.join('analysis','ISTP_demographics_oct21_Aaron_demographicsGroupsFull.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSingleColTree(usedfHuman['gender_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_gender_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['race'].to_frame(), os.path.join('analysis','figures','ISTP_race_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['institution_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_institution_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['primerole_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_role_oct21_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['STEM_oct21'].to_frame(), os.path.join('analysis','figures','ISTP_STEMmed_oct21_tree.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aeef9c",
   "metadata": {},
   "source": [
    "# Third file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata('data/updated_pre.post.consent.modules.completion_FA22.dta')\n",
    "df.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ecca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# role, discipline, institution type, gender,  institution designation, race\n",
    "# (no faculty status in this file?),\n",
    "useCols = [\n",
    "    'primerole_prefall22', 'discipline_prefall22', 'institution_msi_prefall22', \n",
    "    'gender_prefall22', 'institution_prefall22','race_prefall22'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec5197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#usedf = df[useCols]#.dropna(how = 'all').reset_index(drop = True)#.fillna(0)\n",
    "usedf = df.loc[df['completionbinary'] == 1][useCols].reset_index(drop = True)\n",
    "# add an additional column for STEM\n",
    "usedf['STEM_prefall22'] = usedf['discipline_prefall22']\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for indigenous (race == 1)\n",
    "pd.set_option('display.max_rows', 20)\n",
    "col = usedf['race_prefall22']\n",
    "foo = pd.DataFrame(col[col.str.contains('1').fillna(False)])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the NaN values in all the columns\n",
    "Nnan = []\n",
    "for c in useCols:\n",
    "    N1 = usedf[c].isna().sum().sum()\n",
    "    try:\n",
    "        N2 = len(usedf[usedf[c].str.contains('nan')])\n",
    "    except:\n",
    "         N2 = 0\n",
    "    try:\n",
    "        N3 = len(usedf[usedf[c].str.contains(r'^\\s*$', regex = True)])\n",
    "    except:\n",
    "        N3 = 0\n",
    "        \n",
    "    Nnan.append(N1 + N2 + N3)\n",
    "    print(f'# NaN in {c} = {N1 + N2 + N3}')\n",
    "print('')\n",
    "\n",
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole_prefall22':roleMap,\n",
    "    'discipline_prefall22':disciplineMap,\n",
    "    'STEM_prefall22':disciplineSTEMMap,\n",
    "    'institution_prefall22':institutionMap_oct21,\n",
    "    'gender_prefall22':genderMap_prefall22,\n",
    "#     'Q35.1':institutionTypeMap,\n",
    "#     'race':raceMap\n",
    "}\n",
    "\n",
    "usedfHuman = usedf.replace(replacements)\n",
    "\n",
    "# treat the cells with multiple entries a bit differently\n",
    "usedfHuman['institution_msi_prefall22'] = multiReplacer(usedfHuman, 'institution_msi_prefall22', institutionTypeMap)\n",
    "\n",
    "# for race we will put them in the 'Multiracial' category\n",
    "usedfHuman['race_prefall22'].fillna('Did not respond (race)', inplace = True)\n",
    "foo = usedfHuman.loc[usedfHuman['race_prefall22'].str.contains(',')]\n",
    "print('number of people with multiple race entries = ', len(foo))\n",
    "usedfHuman.loc[usedfHuman['race_prefall22'].str.contains(','), 'race_prefall22'] = 'Multiracial' \n",
    "usedfHuman['race_prefall22'] = multiReplacer(usedfHuman, 'race_prefall22', raceMap_prefall22)\n",
    "\n",
    "# remove any extra commas\n",
    "usedfHuman = usedfHuman.applymap(lambda x: str(x).rstrip(', '))\n",
    "\n",
    "# fix any lingering nan values\n",
    "usedfHuman.replace('nan',np.nan, inplace = True)\n",
    "usedfHuman.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "\n",
    "usedfHuman['primerole_prefall22'].fillna('Did not respond (role)', inplace = True)\n",
    "usedfHuman['discipline_prefall22'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['STEM_prefall22'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['institution_prefall22'].fillna('Did not respond (institution)', inplace = True)\n",
    "usedfHuman['gender_prefall22'].fillna('Did not respond (gender)', inplace = True)\n",
    "usedfHuman['institution_msi_prefall22'].fillna('Did not respond (institution type)', inplace = True)\n",
    "# already filled race above\n",
    "\n",
    "# print number of people with did not respond values in all the columns\n",
    "print('')\n",
    "for i, c in enumerate(useCols):\n",
    "    N1 = len(usedfHuman[usedfHuman[c].str.contains('respond')])\n",
    "    print(f'# marked \"prefer not to respond\" {c} = {N1 - Nnan[i]}')\n",
    "    \n",
    "usedfHuman_prefall22 = usedfHuman\n",
    "\n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25190370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = usedfHuman['race_prefall22']\n",
    "foo = pd.DataFrame(col[col.str.contains('Indigenous').fillna(False)])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9e8a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupdf, groupdfTrim, outdf = getDemographics(usedfHuman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982c83ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groupdfTrim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475f687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e69306",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdf.to_csv(os.path.join('analysis','ISTP_demographics_prefall22_Aaron_demographicsGroupsCondensed.csv'), index = False)\n",
    "groupdf.to_csv(os.path.join('analysis','ISTP_demographics_prefall22_Aaron_demographicsGroupsFull.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb738a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "createSingleColTree(usedfHuman['gender_prefall22'].to_frame(), os.path.join('analysis','figures','ISTP_gender_prefall22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['race_prefall22'].to_frame(), os.path.join('analysis','figures','ISTP_race_prefall22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['institution_prefall22'].to_frame(), os.path.join('analysis','figures','ISTP_institution_prefall22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['primerole_prefall22'].to_frame(), os.path.join('analysis','figures','ISTP_role_prefall22_tree.pdf'))\n",
    "createSingleColTree(usedfHuman['STEM_prefall22'].to_frame(), os.path.join('analysis','figures','ISTP_STEMmed_prefall22_tree.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec3b045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeac0843",
   "metadata": {},
   "source": [
    "## Create an input data file for the circle vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1859342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data that we want and rename columns\n",
    "#cols0 = ['primerole_oct21','institution_oct21','gender_oct21','race']\n",
    "cols0 = ['primerole_oct21','institution_oct21','gender_oct21','STEM_oct21','race']\n",
    "circleDfOut = compileCircleData(usedfHuman_oct21[cols0]).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "circleDf = circleDfOut[cols0 + ['count']].copy()\n",
    "circleDf.rename(columns = \n",
    "                {'primerole_oct21':'Role',\n",
    "                   'institution_oct21':'Institution Type',\n",
    "                  'gender_oct21':'Gender',\n",
    "                 'STEM_oct21':'Primary Field',\n",
    "                  'race':'Race'}, \n",
    "                inplace = True)\n",
    "\n",
    "# create the input for the circule visualization\n",
    "circle = createCircleInput(circleDf, ['Role', 'Institution Type', 'Gender', 'Primary Field', 'Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_oct21_circle_data.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n",
    "\n",
    "circleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68255dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "circleDf.loc[circleDf['Primary Field'] == 'Medical sciences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data that we want and rename columns\n",
    "cols0 = ['primerole_march22','institution_march22','gender_march22','STEM_march22','race']\n",
    "circleDfOut = compileCircleData(usedfHuman_march22[cols0]).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "circleDf = circleDfOut[cols0 + ['count']].copy()\n",
    "circleDf.rename(columns = \n",
    "                {'primerole_march22':'Role',\n",
    "                  'institution_march22':'Institution Type',\n",
    "                  'gender_march22':'Gender',\n",
    "                  'STEM_march22':'Primary Field',\n",
    "                  'race':'Race',\n",
    "                }, \n",
    "                inplace = True)\n",
    "\n",
    "# create the input for the circule visualization\n",
    "circle = createCircleInput(circleDf, ['Role', 'Institution Type', 'Gender', 'Primary Field','Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_march22_circle_data.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n",
    "\n",
    "circleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4dcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data that we want and rename columns\n",
    "cols0 = ['primerole_prefall22','institution_prefall22','gender_prefall22','STEM_prefall22','race_prefall22']\n",
    "circleDfOut = compileCircleData(usedfHuman_prefall22[cols0]).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "circleDf = circleDfOut[cols0 + ['count']].copy()\n",
    "circleDf.rename(columns = \n",
    "                {'primerole_prefall22':'Role',\n",
    "                   'institution_prefall22':'Institution Type',\n",
    "                  'gender_prefall22':'Gender',\n",
    "                  'STEM_prefall22':'Primary Field',\n",
    "                  'race_prefall22':'Race'}, \n",
    "                inplace = True)\n",
    "\n",
    "# create the input for the circule visualization\n",
    "circle = createCircleInput(circleDf, ['Role', 'Institution Type', 'Gender', 'Primary Field', 'Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_prefall22_circle_data.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n",
    "\n",
    "circleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43097e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the circle data sets\n",
    "cols0 = ['primerole_oct21','institution_oct21','gender_oct21','STEM_oct21','race']\n",
    "oct21 = usedfHuman_oct21[cols0].rename(columns = \n",
    "                {'primerole_oct21':'Role',\n",
    "                   'institution_oct21':'Institution Type',\n",
    "                  'gender_oct21':'Gender',\n",
    "                 'STEM_oct21':'Primary Field',\n",
    "                  'race':'Race'})\n",
    "\n",
    "cols0 = ['primerole_march22','institution_march22','gender_march22','STEM_march22','race']\n",
    "march22 = usedfHuman_march22[cols0].rename(columns = \n",
    "                {'primerole_march22':'Role',\n",
    "                  'institution_march22':'Institution Type',\n",
    "                  'gender_march22':'Gender',\n",
    "                  'STEM_march22':'Primary Field',\n",
    "                  'race':'Race',\n",
    "                })\n",
    "\n",
    "cols0 = ['primerole_prefall22','institution_prefall22','gender_prefall22','STEM_prefall22','race_prefall22']\n",
    "prefall22 = usedfHuman_prefall22[cols0].rename(columns = \n",
    "                {'primerole_prefall22':'Role',\n",
    "                   'institution_prefall22':'Institution Type',\n",
    "                  'gender_prefall22':'Gender',\n",
    "                  'STEM_prefall22':'Primary Field',\n",
    "                  'race_prefall22':'Race'})\n",
    "\n",
    "\n",
    "combined = pd.concat([oct21, march22, prefall22]).reset_index(drop = True)\n",
    "\n",
    "circleDfOut = compileCircleData(combined).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "# create the input for the circule visualization\n",
    "circle = createCircleInput(circleDfOut, ['Role', 'Institution Type', 'Gender', 'Primary Field', 'Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_combined_circle_data.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n",
    "\n",
    "circleDfOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9c3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any Did Dot Respond entries? (No, I will code this up in the javascript instead)\n",
    "mask = np.column_stack([circleDfOut[col].str.contains(r\"Did not respond\", na = False) for col in circleDfOut.columns[:-1]])\n",
    "circleDfOut.loc[mask.any(axis = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd216dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file that only has the STEM, R1, faculty and will plot gender and Race\n",
    "combined = pd.concat([oct21, march22, prefall22]).reset_index(drop = True)\n",
    "print('all:', len(combined))\n",
    "print('faculty:', len(combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty')]))\n",
    "print('STEM:', len(combined.loc[(combined['Primary Field'] == 'STEM')]))\n",
    "print('research U:', len(combined.loc[(combined['Institution Type'] == 'Research University')]))\n",
    "print('faculty + STEM:', len(combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & (combined['Primary Field'] == 'STEM')]))\n",
    "print('faculty + research U:', len(combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & (combined['Institution Type'] == 'Research University')]))\n",
    "print('STEM + research U:', len(combined.loc[(combined['Primary Field'] == 'STEM') & (combined['Institution Type'] == 'Research University')]))\n",
    "    \n",
    "usedf = combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & \n",
    "                        (combined['Primary Field'] == 'STEM') &\n",
    "                        (combined['Institution Type'] == 'Research University')\n",
    "                       ]\n",
    "\n",
    "print('faculty + research U + STEM:',len(usedf))\n",
    "\n",
    "# create the input for the circle visualization\n",
    "circleDfOut = compileCircleData(usedf).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# # create a file that only has the STEM, R1, faculty and will plot gender and Race\n",
    "# usedf = circleDfOut.loc[(circleDfOut['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & \n",
    "#                         (circleDfOut['Primary Field'] == 'STEM') &\n",
    "#                         (circleDfOut['Institution Type'] == 'Research University')\n",
    "#                        ]\n",
    "# create the input for the circle visualization\n",
    "\n",
    "circle = createCircleInput(circleDfOut, ['Gender','Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_combined_circle_data_STEMR1faculty.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2e87c",
   "metadata": {},
   "source": [
    "# Compare different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb061022",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_comparison_prefall22 = getNodeFractions(usedfHuman_prefall22['gender_prefall22'].to_frame()).rename(columns = {'gender_prefall22':'gender'})\n",
    "gender_comparison_march22 = getNodeFractions(usedfHuman_march22['gender_march22'].to_frame()).rename(columns = {'gender_march22':'gender'})\n",
    "gender_comparison_oct21 = getNodeFractions(usedfHuman_oct21['gender_oct21'].to_frame()).rename(columns = {'gender_oct21':'gender'})\n",
    "gender = gender_comparison_march22.merge(gender_comparison_oct21, on = 'gender', suffixes = ('_march22','_oct21'))\n",
    "gender = gender.merge(gender_comparison_prefall22, on = 'gender').rename(columns = {'count':'count_prefall22','fraction':'fraction_prefall22'})\n",
    "gender = gender.sort_values('count_march22', ascending = False).reset_index(drop = True)\n",
    "gender.to_csv(os.path.join('analysis','gender_fractions_compared.csv'), index = False)\n",
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da87b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "primerole_comparison_prefall22 = getNodeFractions(usedfHuman_prefall22['primerole_prefall22'].to_frame()).rename(columns = {'primerole_prefall22':'primerole'})\n",
    "primerole_comparison_march22 = getNodeFractions(usedfHuman_march22['primerole_march22'].to_frame()).rename(columns = {'primerole_march22':'primerole'})\n",
    "primerole_comparison_oct21 = getNodeFractions(usedfHuman_oct21['primerole_oct21'].to_frame()).rename(columns = {'primerole_oct21':'primerole'})\n",
    "primerole = primerole_comparison_march22.merge(primerole_comparison_oct21, on = 'primerole', suffixes = ('_march22','_oct21'))\n",
    "primerole = primerole.merge(primerole_comparison_prefall22, on = 'primerole').rename(columns = {'count':'count_prefall22','fraction':'fraction_prefall22'})\n",
    "primerole = primerole.sort_values('count_march22', ascending = False).reset_index(drop = True)\n",
    "primerole.to_csv(os.path.join('analysis','primerole_fractions_compared.csv'), index = False)\n",
    "primerole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ccfce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "institution_comparison_prefall22 = getNodeFractions(usedfHuman_prefall22['institution_prefall22'].to_frame()).rename(columns = {'institution_prefall22':'institution'})\n",
    "institution_comparison_march22 = getNodeFractions(usedfHuman_march22['institution_march22'].to_frame()).rename(columns = {'institution_march22':'institution'})\n",
    "institution_comparison_oct21 = getNodeFractions(usedfHuman_oct21['institution_oct21'].to_frame()).rename(columns = {'institution_oct21':'institution'})\n",
    "institution = institution_comparison_march22.merge(institution_comparison_oct21, on = 'institution', suffixes = ('_march22','_oct21'))\n",
    "institution = institution.merge(institution_comparison_prefall22, on = 'institution').rename(columns = {'count':'count_prefall22','fraction':'fraction_prefall22'})\n",
    "institution = institution.sort_values('count_march22', ascending = False).reset_index(drop = True)\n",
    "institution.to_csv(os.path.join('analysis','institution_fractions_compared.csv'), index = False)\n",
    "institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca972a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_comparison_prefall22 = getNodeFractions(usedfHuman_prefall22['race_prefall22'].to_frame()).rename(columns = {'race_prefall22':'race'})\n",
    "race_comparison_march22 = getNodeFractions(usedfHuman_march22['race'].to_frame())\n",
    "race_comparison_oct21 = getNodeFractions(usedfHuman_oct21['race'].to_frame())\n",
    "race = race_comparison_march22.merge(race_comparison_oct21, on = 'race', suffixes = ('_march22','_oct21'))\n",
    "race = race.merge(race_comparison_prefall22, on = 'race').rename(columns = {'count':'count_prefall22','fraction':'fraction_prefall22'})\n",
    "race = race.sort_values('count_march22', ascending = False).reset_index(drop = True)\n",
    "race.to_csv(os.path.join('analysis','race_fractions_compared.csv'), index = False)\n",
    "race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEM_comparison_prefall22 = getNodeFractions(usedfHuman_prefall22['STEM_prefall22'].to_frame()).rename(columns = {'STEM_prefall22':'STEM'})\n",
    "STEM_comparison_march22 = getNodeFractions(usedfHuman_march22['STEM_march22'].to_frame()).rename(columns = {'STEM_march22':'STEM'})\n",
    "STEM_comparison_oct21 = getNodeFractions(usedfHuman_oct21['STEM_oct21'].to_frame()).rename(columns = {'STEM_oct21':'STEM'})\n",
    "STEM = STEM_comparison_march22.merge(STEM_comparison_oct21, on = 'STEM', suffixes = ('_march22','_oct21'))\n",
    "STEM = STEM.merge(STEM_comparison_prefall22, on = 'STEM').rename(columns = {'count':'count_prefall22','fraction':'fraction_prefall22'})\n",
    "STEM = STEM.sort_values('count_march22', ascending = False).reset_index(drop = True)\n",
    "STEM.to_csv(os.path.join('analysis','STEM_fractions_compared.csv'), index = False)\n",
    "STEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25722c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if any are distinct\n",
    "\n",
    "dates = ['march22', 'oct21', 'prefall22']\n",
    "keys = ['gender', 'primerole','institution','race', 'STEM']\n",
    "dfs = [gender, primerole, institution, race, STEM]\n",
    "\n",
    "for usedf, key in zip (dfs, keys):\n",
    "    for i, row in usedf.iterrows():\n",
    "        for j,d1 in enumerate(dates):\n",
    "            for k,d2 in enumerate(dates):\n",
    "                if (j > k):\n",
    "                    # construct a contingency table\n",
    "                    # https://medium.com/mlearning-ai/how-to-perform-chi-square-tests-in-python-e1eabb98ef25\n",
    "                    contingency = construct_contingency(usedf, key, d1, d2, i)\n",
    "                    # perform the chi2 test\n",
    "                    c,p,dof,expected = stats.chi2_contingency(contingency)\n",
    "                    # pdiff = (row[cj] - row[ck])/row[cj]*100.\n",
    "                    # print(d1, d2, row[key], p)\n",
    "                    # if (pdiff > 5.):\n",
    "                    if (p < 0.05):\n",
    "                        print(key, d1, d2, row[key], p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11a566",
   "metadata": {},
   "source": [
    "# Class Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e937894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/NoNames PHYSICS  130-3 - 02  College Physics - SPR 2023.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the student program and plan into two columns\n",
    "df[['College or School','Major']] = df['Student Program and Plan'].str.split('-',expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f01385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "useCols = [\n",
    "    'College or School', 'Acad Level', \n",
    "    'Race/Ethnicity', 'Gender','1st Gen College Student'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedfHuman = df[useCols].copy()\n",
    "usedfHuman.replace({'1st Gen College Student' : 'First Generation College Student'}, 'Yes', inplace=True)\n",
    "usedfHuman.loc[usedfHuman['Race/Ethnicity'].str.contains(','), 'Race/Ethnicity'] = 'Multiracial' \n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1994b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data that we want and rename columns\n",
    "circleDfOut = compileCircleData(usedfHuman).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "circleDf = circleDfOut.copy()\n",
    "\n",
    "# create the input for the circule visualization\n",
    "circle = createCircleInput(circleDf, list(circleDfOut.columns)[:-1])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','PHY130-3-02_SPR2023_circle_data.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n",
    "\n",
    "circleDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd13d09",
   "metadata": {},
   "source": [
    "# Facilitator data (circle vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c074f6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Cleaned_ISTP_Facilitator_Data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to make this easier for me to remember\n",
    "df.rename(columns = { 'Q31':'primerole','Q33':'discipline','Q34':'institution','Q36':'gender','Q35':'institutionType','Q37':'race'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a82a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important columns (trying for same as in the first file)\n",
    "# this does not appear to include the faculty status\n",
    "# They appear to come from the SP22_RQ2_Participant_ISTP.docx file\n",
    "# Q35 (institution designation), Q37 (race) need to be split\n",
    "# role, discipline, institution type, gender, institution designation, race\n",
    "useCols = [\n",
    "    'primerole', 'discipline', 'institution', 'gender', 'institutionType', 'race'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedf = df[useCols].dropna(how = 'all').reset_index(drop = True)#.fillna(0)\n",
    "usedf['STEM'] = usedf['discipline']\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e185119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for indigenous (race == 1)\n",
    "col = usedf['race']\n",
    "col[col.str.contains('1').fillna(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d9759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the NaN values in all the columns\n",
    "Nnan = []\n",
    "for c in useCols:\n",
    "    N1 = usedf[c].isna().sum().sum()\n",
    "    try:\n",
    "        N2 = len(usedf[usedf[c].str.contains('nan')])\n",
    "    except:\n",
    "         N2 = 0\n",
    "    try:\n",
    "        N3 = len(usedf[usedf[c].str.contains(r'^\\s*$', regex = True)])\n",
    "    except:\n",
    "        N3 = 0\n",
    "        \n",
    "    Nnan.append(N1 + N2 + N3)\n",
    "    print(f'# NaN in {c} = {N1 + N2 + N3}')\n",
    "print('')\n",
    "\n",
    "\n",
    "# replace the entries\n",
    "\n",
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole':roleMap,\n",
    "    'discipline':disciplineMap,\n",
    "    'STEM':disciplineSTEMMap,\n",
    "    'institution':institutionMap,\n",
    "    'gender':genderMap,\n",
    "#     'Q35':tenureMap,\n",
    "#     'Q35.1':institutionTypeMap,\n",
    "#     'Q37':raceMap\n",
    "}\n",
    "\n",
    "\n",
    "usedfHuman = usedf.replace(replacements)\n",
    "\n",
    "# treat the cells with multiple entries a bit differently\n",
    "usedfHuman['institutionType'] = multiReplacer(usedfHuman, 'institutionType', institutionTypeMap)\n",
    "\n",
    "# for race we will put them in the 'Multiracial' category\n",
    "usedfHuman['race'].fillna('Did not respond (race)', inplace = True)\n",
    "foo = usedfHuman.loc[usedfHuman['race'].str.contains(',')]\n",
    "print('number of people with multiple race entries = ', len(foo))\n",
    "usedfHuman.loc[usedfHuman['race'].str.contains(','), 'race'] = 'Multiracial' \n",
    "usedfHuman['race'] = multiReplacer(usedfHuman, 'race', raceMap)\n",
    "\n",
    "\n",
    "# remove any extra commas\n",
    "usedfHuman = usedfHuman.applymap(lambda x: str(x).rstrip(', '))\n",
    "\n",
    "# fix any lingering nan values\n",
    "usedfHuman.replace('nan',np.nan, inplace = True)\n",
    "usedfHuman.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "\n",
    "usedfHuman['primerole'].fillna('Did not respond (role)', inplace = True)\n",
    "usedfHuman['discipline'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['institution'].fillna('Did not respond (institution)', inplace = True)\n",
    "usedfHuman['gender'].fillna('Did not respond (gender)', inplace = True)\n",
    "usedfHuman['institutionType'].fillna('Did not respond (institution type)', inplace = True)\n",
    "# already filled race above\n",
    "\n",
    "# print number of people with did not respond values in all the columns\n",
    "print('')\n",
    "for i, c in enumerate(useCols):\n",
    "    N1 = len(usedfHuman[usedfHuman[c].str.contains('respond')])\n",
    "    print(f'# marked \"prefer not to respond\" {c} = {N1 - Nnan[i]}')\n",
    "    \n",
    "usedfHuman_facilitators = usedfHuman\n",
    "\n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270ee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = usedfHuman['race']\n",
    "foo = pd.DataFrame(col[col.str.contains('Indigenous').fillna(False)])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e94b94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data that we want and rename columns\n",
    "cols0 = ['primerole','institution','gender','STEM','race']\n",
    "circleDfOut = compileCircleData(usedfHuman_facilitators[cols0]).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "circleDf = circleDfOut[cols0 + ['count']].copy()\n",
    "circleDf.rename(columns = \n",
    "                {'primerole':'Role',\n",
    "                'institution':'Institution Type',\n",
    "                'gender':'Gender',\n",
    "                'STEM':'Primary Field',\n",
    "                'race':'Race'}, \n",
    "                inplace = True)\n",
    "\n",
    "# create the input for the circule visualization\n",
    "circle = createCircleInput(circleDf, ['Role', 'Institution Type', 'Gender', 'Primary Field', 'Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_facilitator_circle_data.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n",
    "\n",
    "circleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3af4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42f71b76",
   "metadata": {},
   "source": [
    "# Participant data (circle vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/Cleaned_ISTP_Participant_Data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed8b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to make this easier for me to remember\n",
    "df.rename(columns = { 'Q31':'primerole','Q33.1':'discipline','Q34.1':'institution','Q36':'gender','Q35.1':'institutionType','Q37':'race'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11696e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important columns (trying for same as in the first file)\n",
    "# this does not appear to include the faculty status\n",
    "# They appear to come from the SP22_RQ2_Participant_ISTP.docx file\n",
    "# Q35 (institution designation), Q37 (race) need to be split\n",
    "# role, discipline, institution type, gender, institution designation, race\n",
    "useCols = [\n",
    "    'primerole', 'discipline', 'institution', 'gender', 'institutionType', 'race'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b464c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "usedf = df[useCols].dropna(how = 'all').reset_index(drop = True)#.fillna(0)\n",
    "usedf['STEM'] = usedf['discipline']\n",
    "usedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299f66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for indigenous (race == 1)\n",
    "col = usedf['race']\n",
    "col[col.str.contains('1').fillna(False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5647dcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the NaN values in all the columns\n",
    "Nnan = []\n",
    "for c in useCols:\n",
    "    N1 = usedf[c].isna().sum().sum()\n",
    "    try:\n",
    "        N2 = len(usedf[usedf[c].str.contains('nan')])\n",
    "    except:\n",
    "         N2 = 0\n",
    "    try:\n",
    "        N3 = len(usedf[usedf[c].str.contains(r'^\\s*$', regex = True)])\n",
    "    except:\n",
    "        N3 = 0\n",
    "        \n",
    "    Nnan.append(N1 + N2 + N3)\n",
    "    print(f'# NaN in {c} = {N1 + N2 + N3}')\n",
    "print('')\n",
    "\n",
    "\n",
    "# replace the entries\n",
    "\n",
    "# replace numbers with values\n",
    "replacements = {\n",
    "    'primerole':roleMap,\n",
    "    'discipline':disciplineMap,\n",
    "    'STEM':disciplineSTEMMap,\n",
    "    'institution':institutionMap,\n",
    "    'gender':genderMap,\n",
    "#     'Q35':tenureMap,\n",
    "#     'Q35.1':institutionTypeMap,\n",
    "#     'Q37':raceMap\n",
    "}\n",
    "\n",
    "\n",
    "usedfHuman = usedf.replace(replacements)\n",
    "\n",
    "# treat the cells with multiple entries a bit differently\n",
    "usedfHuman['institutionType'] = multiReplacer(usedfHuman, 'institutionType', institutionTypeMap)\n",
    "\n",
    "# for race we will put them in the 'Multiracial' category\n",
    "usedfHuman['race'].fillna('Did not respond (race)', inplace = True)\n",
    "foo = usedfHuman.loc[usedfHuman['race'].str.contains(',')]\n",
    "print('number of people with multiple race entries = ', len(foo))\n",
    "usedfHuman.loc[usedfHuman['race'].str.contains(','), 'race'] = 'Multiracial' \n",
    "usedfHuman['race'] = multiReplacer(usedfHuman, 'race', raceMap)\n",
    "\n",
    "\n",
    "# remove any extra commas\n",
    "usedfHuman = usedfHuman.applymap(lambda x: str(x).rstrip(', '))\n",
    "\n",
    "# fix any lingering nan values\n",
    "usedfHuman.replace('nan',np.nan, inplace = True)\n",
    "usedfHuman.replace(r'^\\s*$', np.nan, regex = True, inplace = True)\n",
    "\n",
    "usedfHuman['primerole'].fillna('Did not respond (role)', inplace = True)\n",
    "usedfHuman['discipline'].fillna('Did not respond (discipline)', inplace = True)\n",
    "usedfHuman['institution'].fillna('Did not respond (institution)', inplace = True)\n",
    "usedfHuman['gender'].fillna('Did not respond (gender)', inplace = True)\n",
    "usedfHuman['institutionType'].fillna('Did not respond (institution type)', inplace = True)\n",
    "# already filled race above\n",
    "\n",
    "# print number of people with did not respond values in all the columns\n",
    "print('')\n",
    "for i, c in enumerate(useCols):\n",
    "    N1 = len(usedfHuman[usedfHuman[c].str.contains('respond')])\n",
    "    print(f'# marked \"prefer not to respond\" {c} = {N1 - Nnan[i]}')\n",
    "    \n",
    "usedfHuman_participants = usedfHuman\n",
    "\n",
    "usedfHuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = usedfHuman['race']\n",
    "foo = pd.DataFrame(col[col.str.contains('Indigenous').fillna(False)])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1221d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data that we want and rename columns\n",
    "cols0 = ['primerole','institution','gender','STEM','race']\n",
    "circleDfOut = compileCircleData(usedfHuman[cols0]).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "circleDf = circleDfOut[cols0 + ['count']].copy()\n",
    "circleDf.rename(columns = \n",
    "                {'primerole':'Role',\n",
    "                'institution':'Institution Type',\n",
    "                'gender':'Gender',\n",
    "                'STEM':'Primary Field',\n",
    "                'race':'Race'}, \n",
    "                inplace = True)\n",
    "\n",
    "# create the input for the circule visualization\n",
    "circle = createCircleInput(circleDf, ['Role', 'Institution Type', 'Gender', 'Primary Field', 'Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_participant_circle_data.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n",
    "\n",
    "circleDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacc3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file that only has the STEM, R1, faculty and will plot gender and Race\n",
    "cols0 = ['primerole','institution','gender','STEM','race']\n",
    "combined = usedfHuman[cols0].copy()\n",
    "combined.rename(columns = \n",
    "                {'primerole':'Role',\n",
    "                'institution':'Institution Type',\n",
    "                'gender':'Gender',\n",
    "                'STEM':'Primary Field',\n",
    "                'race':'Race'}, inplace = True)\n",
    "\n",
    "print('all:', len(combined))\n",
    "print('faculty:', len(combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty')]))\n",
    "print('STEM:', len(combined.loc[(combined['Primary Field'] == 'STEM')]))\n",
    "print('research U:', len(combined.loc[(combined['Institution Type'] == 'Research University')]))\n",
    "print('faculty + STEM:', len(combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & (combined['Primary Field'] == 'STEM')]))\n",
    "print('faculty + research U:', len(combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & (combined['Institution Type'] == 'Research University')]))\n",
    "print('STEM + research U:', len(combined.loc[(combined['Primary Field'] == 'STEM') & (combined['Institution Type'] == 'Research University')]))\n",
    "    \n",
    "usedf = combined.loc[(combined['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & \n",
    "                        (combined['Primary Field'] == 'STEM') &\n",
    "                        (combined['Institution Type'] == 'Research University')\n",
    "                       ]\n",
    "\n",
    "print('faculty + research U + STEM:',len(usedf))\n",
    "\n",
    "# create the input for the circle visualization\n",
    "circleDfOut = compileCircleData(usedf).sort_values(by = 'count', ascending = False).reset_index(drop = True)\n",
    "\n",
    "\n",
    "# # create a file that only has the STEM, R1, faculty and will plot gender and Race\n",
    "# usedf = circleDfOut.loc[(circleDfOut['Role'] == 'Faculty member, lecturer, instructor, or adjunct faculty') & \n",
    "#                         (circleDfOut['Primary Field'] == 'STEM') &\n",
    "#                         (circleDfOut['Institution Type'] == 'Research University')\n",
    "#                        ]\n",
    "# create the input for the circle visualization\n",
    "\n",
    "circle = createCircleInput(circleDfOut, ['Gender','Race'])\n",
    "with open(os.path.join('demographics_circle_plot', 'src','data','ISTP_demographics_participant_circle_data_STEMR1faculty.json'), 'w') as outfile:\n",
    "    json_object = json.dumps(circle)\n",
    "    outfile.write(json_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84361a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
