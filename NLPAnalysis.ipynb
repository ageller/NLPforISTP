{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c552a5",
   "metadata": {},
   "source": [
    "# NLP analysis\n",
    "\n",
    "```\n",
    "conda create --name NLP -c conda-forge python=3.10 jupyter pandas numpy matplotlib openpyxl nltk gensim pyldavis spacy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e87faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you are running this for the first time on a new installation, uncomment below and run this cell\n",
    "## (This only needs to be run once.)\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "# import spacy\n",
    "# spacy.cli.download('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b589ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b3efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import my code (and set to autoreload <-- only necessary while coding/debugging)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from NLPforISP import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0681f1cd",
   "metadata": {},
   "source": [
    "## Read in the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68559a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data file with multiple sheets\n",
    "filename = 'data/ITP_CourseArtifacts_June 2021_END_of_Course_DeIDENTIFIED.xlsx'\n",
    "\n",
    "# sheet name for this analysis, containing responses to one question\n",
    "#sheet = 'Course Meta SelfEff'\n",
    "sheet = 'Course Meta App'\n",
    "\n",
    "df = pd.read_excel(filename, sheet)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c0337",
   "metadata": {},
   "source": [
    "## Get the bigrams and trigrams and create bar charts of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16366eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add appropriate words that will be ignored in the analysis\n",
    "additional_stopwords = ['1', '2', 'one', 'two', 'etc']\n",
    "\n",
    "# get a string of the words contained in all the answers from this DataFrame\n",
    "string_of_answers = getStringOfWords(df, 1)\n",
    "\n",
    "# get the bigrams and trigrams\n",
    "bigrams = getNgrams(string_of_answers, 2, additional_stopwords = additional_stopwords)\n",
    "trigrams = getNgrams(string_of_answers, 3, additional_stopwords = additional_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a13508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a plot of the bigrams and trigrams\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "N = 20\n",
    "plotNgrams(bigrams, N, ax = ax1)\n",
    "plotNgrams(trigrams, N, ax = ax2)\n",
    "_ = ax1.set_title(str(N) + ' Most Frequently Occuring Bigrams')\n",
    "_ = ax2.set_title(str(N) + ' Most Frequently Occuring Trigrams')\n",
    "plt.subplots_adjust(wspace = 0.6, left = 0.15, right = 0.99, top = 0.95, bottom = 0.07)\n",
    "\n",
    "f.savefig('ngrams_' + sheet.replace(' ','') + '.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee5820",
   "metadata": {},
   "source": [
    "## Topic modeling\n",
    "\n",
    "Using NLTK + gensim,  Latent Dirichlet Allocation (LDA) algorithm, which uses unsupervised learning to extract the main topics (i.e., a set of words) that occur in a collection of text samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c9c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the topic model (which also generates a \"dictionary\" and a \"bag of words\")\n",
    "dictionary, bow_corpus, lda_model, perplexity, coherence = runLDATopicModel(df, 1, 5, workers = 6, \n",
    "    additional_stopwords = additional_stopwords, no_below = 15, no_above = 1, keep_n = int(1e5),\n",
    "    random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6294899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dictionary\n",
    "printDictionary(dictionary, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3b5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the bag of words\n",
    "printBagOfWords(dictionary, bow_corpus, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the topic model\n",
    "printLDATopicModel(lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f47dfaa",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Run a series of LDA models and plot the coherence and perplexity scores to try to identify the optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756179c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = np.arange(10) + 1\n",
    "dictionary, bow_corpus, lda_model, perplexity, coherence = runLDATopicModel(df, 1, num_topics, workers = 6, \n",
    "    additional_stopwords = additional_stopwords, no_below = 15, no_above = 1, keep_n = int(1e5),\n",
    "    random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0a3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the index of the best model by selecting the maximum coherence score\n",
    "# choose the 'c_v' measure of coherence for this\n",
    "\n",
    "best_index = np.argmax(coherence['c_v'])\n",
    "num_topics[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18077003",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the results\n",
    "# higher coherence is better\n",
    "# lower perplexity is better\n",
    "\n",
    "f, (ax1, ax2) = plotLDAMetrics(num_topics, coherence, perplexity, best_index)\n",
    "f.savefig('metrics_' + sheet.replace(' ','') + '.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13965aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the probabilities for each answer being in each topic\n",
    "df_p = getLDAProbabilities(lda_model[best_index], bow_corpus, df, 1)\n",
    "df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4549b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a KDE of the probability distributions for each topic\n",
    "f, ax = plotTopLDAProbabilitiesKDE(df_p)#, bw_method = 0.3)\n",
    "f.savefig('probabilities_' + sheet.replace(' ','') + '.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab068974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get summary information about the topics\n",
    "df_p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92319578",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print the answers that have the maximum probability for each topic\n",
    "printBestLDATopicSentences(df_p, dictionary, lda_model[best_index], n_answers = 20, n_sentences = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4b9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d4b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d6802f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e622e195",
   "metadata": {},
   "source": [
    "## Visualization using pyLDAvis\n",
    "\n",
    "- https://nbviewer.org/github/bmabey/hacker_news_topic_modelling/blob/master/HN%20Topic%20Model%20Talk.ipynb\n",
    "- https://github.com/bmabey/pyLDAvis\n",
    "- https://nbviewer.org/github/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb\n",
    "\n",
    "Most of the visualization is self expanatory, but the slider to adjust the \"relevant metric\" takes some reading. \n",
    "From here: https://we1s.ucsb.edu/research/we1s-tools-and-software/topic-model-observatory/tmo-guide/tmo-guide-pyldavis/\n",
    "\n",
    "\"A “relevance metric” slider scale at the top of the right panel controls how the words for a topic are sorted. As defined in the article by Sievert and Shirley (the creators of LDAvis, on which pyLDAvis is based), “relevance” combines two different ways of thinking about the degree to which a word is associated with a topic:\n",
    "\n",
    "On the one hand, we can think of a word as highly associated with a topic if its frequency in that topic is high. By default the lambda (λ) value in the slider is set to “1,” which sorts words by their frequency in the topic (i.e., by the length of their red bars).\n",
    "\n",
    "On the other hand, we can think of a word as highly associated with a topic if its “lift” is high. “Lift”–a term that Sievert and Shirley borrow from research on topic models by others–means basically how much a word’s frequency sticks out in a topic above the baseline of its overall frequency in the model (i.e., the “the ratio of a term’s probability within a topic to its marginal probability across the corpus,” or the ratio between its red bar and blue bar).\n",
    "\n",
    "By default, pyLDAvis is set for λ = 1, which sorts words just by their frequency within the specific topic (by their red bars).  By contrast, setting λ = 0 words sorts words by their “lift. This means that words whose red bars are nearly as long as their blue bars will be sorted at the top. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c5964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf6cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3af8ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Note: I chose the best index from the lda_models array while plotting the coherence and perplexity metrics\n",
    "pyLDAvis.gensim_models.prepare(lda_model[best_index], bow_corpus, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992ff977",
   "metadata": {},
   "source": [
    "## Term Frequency – Inverse Document Frequency (TF-IDF) analysis\n",
    "\n",
    "TF-IDF (using sci-kit learn’s TfidfVectorizer) measures the frequency of a word in a document and compares it to the frequencies of all words in the text to assign it a weighted score of importance.\n",
    "\n",
    "https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/03-TF-IDF-Scikit-Learn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15dd2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the answers column to a list\n",
    "list_of_answers = df[df.columns[1]].tolist() \n",
    "\n",
    "# preprocess each answer separately\n",
    "processed_answers = []\n",
    "for answer in list_of_answers:\n",
    "    processed_answers.append(' '.join(preprocess(answer, additional_stopwords = additional_stopwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the answers column to a list\n",
    "list_of_answers = df[df.columns[1]].tolist() \n",
    "\n",
    "# preprocess each answer separately\n",
    "processed_answers = []\n",
    "for answer in list_of_answers:\n",
    "    processed_answers.append(' '.join(preprocess(answer, additional_stopwords = additional_stopwords)))\n",
    "    \n",
    "#TF-IDF (word level)\"\"\n",
    "vectorizer = TfidfVectorizer(analyzer='word')\n",
    "tfidf_vector = vectorizer.fit_transform(processed_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612de2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_vector.toarray(), columns = vectorizer.get_feature_names())\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef686fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit to only the most important words\n",
    "# take words that appear in at least 1% of the answers\n",
    "lim = 0.01*tfidf_df.shape[0]\n",
    "tfidf_df_cull = tfidf_df.loc[(tfidf_df.sum(axis=1) != 0), (tfidf_df.sum(axis=0) >= lim)]\n",
    "tfidf_df_cull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c663fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb0fda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76d3dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b1b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b4e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21f34c99",
   "metadata": {},
   "source": [
    "#  TODO\n",
    "\n",
    "\n",
    "## Try Mallet LDA?\n",
    "\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/ <-- this also contains some great additional steps to check out\n",
    "\n",
    "Following steps from here : https://radimrehurek.com/gensim_3.8.3/models/wrappers/ldamallet.html\n",
    "\n",
    "(Working in WSL to compile the Mallet code.)\n",
    "\n",
    "```\n",
    "sudo apt update\n",
    "sudo apt-get install default-jdk\n",
    "git clone https://github.com/mimno/Mallet.git\n",
    "cd Mallet/\n",
    "ant\n",
    "```\n",
    "\n",
    "But this doesn't exist in gensim anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84983a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_mallet_binary = \"/c/Users/ageller/NUIT/projects/BennettGoldberg/Mallet/bin/mallet\"\n",
    "\n",
    "dictionary, bow_corpus, processed_answers = getBagOfWords(df, 1,  additional_stopwords = additional_stopwords, no_below = 15, no_above = 1, keep_n = int(1e5))\n",
    "\n",
    "model = gensim.models.wrappers.LdaMallet(path_to_mallet_binary, corpus = bow_corpus, num_topics = 5, \n",
    "                                         id2word = dictionary)\n",
    "vector = model[common_corpus[0]]  # LDA topics of a documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072469ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
