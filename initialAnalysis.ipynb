{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c552a5",
   "metadata": {},
   "source": [
    "# Initial NLP analysis\n",
    "\n",
    "```\n",
    " conda create --name NLP -c conda-forge python=3.10 jupyter pandas numpy matplotlib openpyxl textBlob nltk\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b589ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68559a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data file with multiple sheets\n",
    "filename = 'data/ITP_CourseArtifacts_June 2021_END_of_Course_DeIDENTIFIED.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9070b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheet name for this analysis, containing responses to one question\n",
    "sheet = 'Course Meta SelfEff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7685bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(filename, sheet)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8fa03f",
   "metadata": {},
   "source": [
    "## Look for n-grams\n",
    "\n",
    "- NLTK (followed this): https://towardsdatascience.com/from-dataframe-to-n-grams-e34e29df3460\n",
    "- textBlob (haven't tried) : https://levelup.gitconnected.com/simple-nlp-in-python-f5196db63aff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b41b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e87faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only needs to be run once\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d585ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add appropriate words that will be ignored in the analysis\n",
    "ADDITIONAL_STOPWORDS = ['1', '2', 'one', 'two', 'etc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb209744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    \"\"\"\n",
    "    A simple function to clean up the data. All the words that\n",
    "    are not designated as a stop word is then lemmatized after\n",
    "    encoding and basic regex parsing are performed.\n",
    "    \n",
    "    from here : https://towardsdatascience.com/from-dataframe-to-n-grams-e34e29df3460\n",
    "    \"\"\"\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english') + ADDITIONAL_STOPWORDS\n",
    "    text = (unicodedata.normalize('NFKD', text)\n",
    "        .encode('ascii', 'ignore')\n",
    "        .decode('utf-8', 'ignore')\n",
    "        .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d002872d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the words in order (excluding the stop words)\n",
    "words = basic_clean(''.join(str(df[df.columns[1]].tolist())))\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2991bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bigrams\n",
    "bigrams = pd.Series(nltk.ngrams(words, 2)).value_counts()\n",
    "bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d33868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the trigrams\n",
    "trigrams = pd.Series(nltk.ngrams(words, 3)).value_counts()\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b60eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "\n",
    "N = 20\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "ind = np.arange(N)\n",
    "\n",
    "bigrams_plot = bigrams[0:N].sort_values()\n",
    "ax1.barh(ind, bigrams_plot, 0.9, color = 'gray')\n",
    "ax1.set_yticks(ind)\n",
    "_ = ax1.set_yticklabels(bigrams_plot.index.str.join(sep=' '))\n",
    "_ = ax1.set_title(str(N) + ' Most Frequently Occuring Bigrams')\n",
    "_ = ax1.set_xlabel('# of Occurances')\n",
    "\n",
    "trigrams_plot = trigrams[0:N].sort_values()\n",
    "ax2.barh(ind, trigrams_plot, 0.9, color = 'gray')\n",
    "ax2.set_yticks(ind)\n",
    "_ = ax2.set_yticklabels(trigrams_plot.index.str.join(sep=' '))\n",
    "_ = ax2.set_title(str(N) + ' Most Frequently Occuring Trigrams')\n",
    "_ = ax2.set_xlabel('# of Occurances')\n",
    "\n",
    "plt.subplots_adjust(wspace = 0.9, left = 0.15, right = 0.99, top = 0.95, bottom = 0.07)\n",
    "\n",
    "plt.savefig('ngrams.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee5820",
   "metadata": {},
   "source": [
    "## Topic modeling\n",
    "\n",
    "- NLTK and gensim : https://towardsdatascience.com/nlp-extracting-the-main-topics-from-your-dataset-using-lda-in-minutes-21486f5aa925\n",
    "- NLTK and gensim : https://towardsdatascience.com/introduction-to-nlp-part-5b-unsupervised-topic-model-in-python-ab04c186f295\n",
    "- pyLDAvis : https://www.projectpro.io/article/10-nlp-techniques-every-data-scientist-should-know/415#toc-10\n",
    "- pyLDAvis : https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1934bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
